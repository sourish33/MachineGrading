{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import random\n",
    "import time\n",
    "\n",
    "#All Function definitions\n",
    "\n",
    "def generateIDs(keyname, numberOfQuestions):\n",
    "    '''generates a unique ID for each question using the beginning characters of each question'''\n",
    "    goodIDs=[]\n",
    "    with open(keyname) as file:  \n",
    "        data = file.read()\n",
    "    for n in range(1,numberOfQuestions+1):\n",
    "            #print(\"processing: \"+str(n))\n",
    "            locs=[]\n",
    "            occursat=find_all(data, str(n)+')')\n",
    "            for ii in occursat:\n",
    "                if data[ii-1]=='\\r' or data[ii-1]=='\\n'  and data[ii+3]!=\"_\":# check for both /r and /n\n",
    "                    locs.append(ii)\n",
    "                    #print(locs)\n",
    "            z=lambda x: str('0')+str(x) if x<10 else str(x)\n",
    "            theID=z(n)+\"_\"+(data[locs[0]+3:locs[0]+25]).strip()\n",
    "            goodIDs.append(theID)\n",
    "    return goodIDs\n",
    "\n",
    "def unduplicate(dup_list):\n",
    "    '''finds duplicate entries in a list and adds characters to duplicated entries to make them unique.\n",
    "    works in a roundabout way by converting to a dataframe first , and then converting back to a list in the end'''\n",
    "    df = pd.DataFrame(dup_list)\n",
    "    dups=df[df.duplicated(keep='first')]\n",
    "    if not dups.empty:\n",
    "        dup_indices=list(dups.index)\n",
    "        for i in dup_indices:\n",
    "            df.iat[i,0]=df.iat[i,0]+str(i)\n",
    "            print(\"Unduplicating: \"+ df.iat[i,0])\n",
    "    undup_list=list(df.values.flatten())\n",
    "    return undup_list\n",
    "\n",
    "def createQuestionIDs(numberOfQuestions):\n",
    "    '''this will generateIDs unique question IDs for each question from the raw keys'''\n",
    "    allIDs=[]\n",
    "    for n in range(0,6):\n",
    "        filename=\"key\"+str(n)+\".txt\"\n",
    "        if (os.path.isfile(filename)): \n",
    "            qid=generateIDs(filename,numberOfQuestions)\n",
    "            allIDs.append(qid)\n",
    "    allIDs[0]=unduplicate(allIDs[0])\n",
    " #The ID's generated are slightly different in each version, so set them all equal to the ID's in version0           \n",
    "    for n in range(1,numberOfVersions):\n",
    "        for m in range(0,numberOfQuestions):\n",
    "            sub=allIDs[0][m][4:20]\n",
    "            matching = [s for s in allIDs[n] if sub in s]\n",
    "            found_in=allIDs[n].index(matching[0])\n",
    "            if allIDs[n][found_in]!=allIDs[0][m]:\n",
    "                #print(QIDs[n][found_in]+\"   changed to    \"+QIDs[0][m])\n",
    "                allIDs[n][found_in]=allIDs[0][m]\n",
    "    \n",
    "    return allIDs\n",
    "\n",
    "def find_all(a_str, sub):\n",
    "    '''finds all instances of a substring in a string'''\n",
    "    start = 0\n",
    "    result=[]\n",
    "    while True:\n",
    "        start = a_str.find(sub, start)\n",
    "        if start == -1: return result\n",
    "        result.append(start)\n",
    "        start += len(sub) # use start += 1 to find overlapping matches\n",
    "    return result\n",
    "\n",
    "def cleanKey(key_name):\n",
    "    '''retrieves just the \"key\" part of exported test. \n",
    "    Just reads and returns the key if the questions have already been deleted \n",
    "    writes to a new file with name cleankey'''\n",
    "    if(os.path.isfile(key_name)):\n",
    "        #print(\"Scrubbing: \"+key_name+\" which is :\" + str(type(key_name)))\n",
    "        with open(key_name) as file:  \n",
    "            data = file.read()\n",
    "            p=data.rfind('_____')\n",
    "            if p!=-1: \n",
    "                data=data[p+5:]#delete all the junk before \"_______\"\n",
    "                data=data[data.find('1)'):]#keep all the stuff after the 1)\n",
    "    endline=['\\rID:', '\\nID:']\n",
    "    for pp in endline:\n",
    "        if data.find(pp)!=-1:# remove the question ID to a separate column if necessary\n",
    "            data = data.replace(pp,'\\t')\n",
    "    with open('cleaned_'+key_name, 'w') as file:\n",
    "        file.write(data)\n",
    "        \n",
    "def getAllKeys():\n",
    "    '''read all files named key0-key4, make them into strings and and return a dictionary\n",
    "    containing a list of keys and also the number of questions'''\n",
    "    keylist=[]\n",
    "\n",
    "    for n in range(0,6):\n",
    "        filename=\"key\"+str(n)+\".txt\"\n",
    "        #print(\"processing: \"+filename)\n",
    "        if os.path.isfile(filename): \n",
    "            cleanKey(filename)#always create a fresh cleankey, to avoid using an outdated one\n",
    "            keys=pd.read_table(\"cleaned_\"+filename, header=None,usecols=[0])\n",
    "            keylist.append(makekey(keys))\n",
    "    numberOfQuestions=keys.shape[0]\n",
    "    getAllKeysOutput={\"keylist\":keylist,\"numberOfQuestions\":numberOfQuestions}\n",
    "    return getAllKeysOutput\n",
    "\n",
    "\n",
    "def makekey(key_from_test):\n",
    "    '''key_from_test is a dataframe formed from reading the answerkey file. This function converts it into a text string with numbers 0-5 representing A-E'''\n",
    "    #keydictionary={\"A\":\"0\",\"B\":\"1\",\"C\":\"2\",\"D\":\"3\",\"E\":\"4\"}\n",
    "    thekey=\"\"\n",
    "    for i in range(0,key_from_test.shape[0]):\n",
    "        #print(\"At i=\"+str(i))\n",
    "        #get the last letter, i.e. the \"C\" from \"1)C\" \n",
    "        thekey+=keydictionary[key_from_test.iat[i,0][-1:]]\n",
    "    return thekey\n",
    "\n",
    "\n",
    "def gradeWithKeylist(keylist, ans, numberOfQuestions, QIDs, points=[], analysis=False):\n",
    "    '''multiple versions - find the correct key as indicated on the last question on the exam '''\n",
    "    assert(keylist!=[])\n",
    "    whichKey=int(ans[-1:])\n",
    "    key=keylist[whichKey]\n",
    "    assert len(key)==len(ans)\n",
    "    missed=\"\"\n",
    "    #invkeydictionary={0:\"A\",1:\"B\",2:\"C\",3:\"D\",4:\"E\"}\n",
    "    rejalt=[1]*numberOfQuestions\n",
    "    for n in range(0,len(key)-1):\n",
    "        if key[n]!=ans[n]:\n",
    "            #print(\"storing\")\n",
    "            missed+=str(n+1)+\", \"\n",
    "            rejalt[n]=0\n",
    "    if sum(rejalt)==numberOfQuestions:\n",
    "        missed=\"ALL CORRECT\"\n",
    "    else:\n",
    "        missed=\"v\"+invkeydictionary[whichKey]+\": \"+missed[:len(missed)-2]\n",
    "    \n",
    "\n",
    "    mydict1 = dict(zip(QIDs[whichKey],rejalt))\n",
    "    sortedIDs=sorted(mydict1.keys())\n",
    "    sorted_rejalt=[mydict1[k] for k in sortedIDs]####its sorted according to v0\n",
    "    \n",
    "    if not points:\n",
    "        points=[1]*numberOfQuestions   \n",
    "    points[-1]=0 #No points for the test version\n",
    "    score=sum([i*j for i,j in zip(points,sorted_rejalt)])\n",
    "    \n",
    "    if analysis:\n",
    "        global analysis_df     \n",
    "        sorted_rejalt.append(score)\n",
    "        analysis_df.loc[len(analysis_df)] = sorted_rejalt \n",
    "        \n",
    "        global allAnswers_df\n",
    "        mydict2 = dict(zip(QIDs[whichKey],ans))  \n",
    "        sortedIDs=sorted(mydict2.keys())\n",
    "        sorted_ans=[mydict2[k] for k in sortedIDs]\n",
    "        allAnswers_df.loc[len(allAnswers_df)] = sorted_ans\n",
    "    \n",
    "\n",
    "        \n",
    "    return {'missed':missed, 'score':score}\n",
    "\n",
    "def process_grades(keylist,data,numberOfQuestions, QIDs, points=[], analysis=False):\n",
    "    '''grades all exams using correct keys, writes questions missed and scores'''\n",
    "    for NN in range(0, data.shape[0]):\n",
    "        #print(\"NN: \"+str(NN))\n",
    "        check1=gradeWithKeylist(keylist, df.iat[NN,2], numberOfQuestions, QIDs, points, analysis)\n",
    "        data.iat[NN,3]=check1['missed']\n",
    "        data.iat[NN,4]=check1['score']\n",
    "    if QIDs:\n",
    "        global analysis_df\n",
    "        analysis_df.drop(analysis_df.columns[analysis_df.shape[1]-2], axis=1, inplace=True)\n",
    "      \n",
    "    return data\n",
    "\n",
    "\n",
    "def count_how_many(col, value):\n",
    "    '''takes a pandas series \"col\" and counts the number of instances of a \"value\" \n",
    "    Not used since pandas has a built-in function'''\n",
    "    \n",
    "    count=0\n",
    "    for n in range(0,col.shape[0]):\n",
    "        if col[n]==value:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "def addStarsToCorrectChoices(rdf, keylist, m, QIDS):\n",
    "    '''adds stars to correct choices in rdf'''\n",
    "    for n in range(0,rdf.shape[0]):\n",
    "        if m!=0:\n",
    "            mydict0 = dict(zip(QIDs[m],keylist[m])) \n",
    "            sortedkey=[mydict0[x] for x in QIDs[0]]\n",
    "        else:\n",
    "            sortedkey=keylist[m]\n",
    "        the_correct_answer=sortedkey[n]\n",
    "        rdf.iloc[n][the_correct_answer]=rdf.iloc[n][the_correct_answer]+\"*\"\n",
    "    return rdf\n",
    "\n",
    "def analyse_items(a_df, QIDs):\n",
    "    '''create separate dfs with how many marked correct for each version separately'''\n",
    "    vers=['0','1','2','3','4']\n",
    "    lvers=['A','B','C','D','E']\n",
    "    outvars=[]\n",
    "    print(\"Versions found:\")\n",
    "    for n in range(0,len(vers)):\n",
    "        ch=str(n)\n",
    "        ##check the last column \"which version...\" to find the version and see if it matches ch\n",
    "        part_df = a_df.loc[allAnswers_df[list(allAnswers_df)[-1]]==ch]\n",
    "        if not part_df.empty:\n",
    "            print(lvers[n])\n",
    "            part_df=part_df.T\n",
    "            part_df=part_df.apply(pd.Series.value_counts, axis=1).fillna(0)\n",
    "            part_df=part_df.applymap(str)\n",
    "            part_df=addStarsToCorrectChoices(part_df,keylist,n, QIDs)\n",
    "            if ' ' in list(part_df):\n",
    "                part_df.rename(columns={' ': 'blank'}, inplace=True)   \n",
    "            for pp in vers:\n",
    "                if pp in list(part_df):\n",
    "                    part_df.rename(columns={pp: lvers[int(pp)]}, inplace=True)\n",
    "            outvars.append(part_df)\n",
    "        else:\n",
    "            print(lvers[n]+\" not found\")\n",
    "        \n",
    "    return outvars\n",
    "\n",
    "\n",
    " ####################### SUGGESTED USAGE#################################\n",
    "# outs = getAllKeys()\n",
    "# keylist=outs[\"keylist\"]\n",
    "# numberOfQuestions=outs[\"numberOfQuestions\"] \n",
    "# numberOfVersions=len(keylist)\n",
    "\n",
    "# QIDs=createQuestionIDs(numberOfQuestions)\n",
    "# analysis_df  = pd.DataFrame(columns = QIDs[0])\n",
    "#count_how_many(allAnswers_df.iloc[12,:] , ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually convert the dat file into an excel file using excel. Only extract the serial number,\n",
    "name and Answers, and make sure Answers is text.\n",
    "Do the following by hand:\n",
    "check serial numbers (using remove duplicates)\n",
    "manually fill in missing information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Srl No               Name                     Answers\n",
      "31     1034      PASCAL JOEZER  2041232433101420044 214422\n",
      "192    2043  LAMBERT DOMINIC E  103020224314 1312213210120\n",
      "253    2127  IKEDIONWU MUNACHI  103222121102013144032211 0\n"
     ]
    }
   ],
   "source": [
    "#COLLECTING DATA\n",
    "rawdatafilename='All'\n",
    "xls_file = pd.ExcelFile(rawdatafilename+'.xlsx', dtype=str)\n",
    "df = xls_file.parse('Sheet1', header=None, parse_cols=2,names = [\"Srl No\", \"Name\", \"Answers\"])\n",
    "#parse_cols makes sure that only cols 0,1 and 2 are extracted\n",
    "#checking for blanks, print only if blanks found\n",
    "if not df[df['Answers'].str.contains(\" \")].empty:\n",
    "    print(df[df['Answers'].str.contains(\" \")])\n",
    "df[\"Missed\"] = \"\"\n",
    "df[\"Score\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions found:\n",
      "A\n",
      "B\n",
      "C\n",
      "D not found\n",
      "E not found\n",
      "That took: 1.4002532958984375 sec\n"
     ]
    }
   ],
   "source": [
    "#here is where we run the code\n",
    "keydictionary={\"A\":\"0\",\"B\":\"1\",\"C\":\"2\",\"D\":\"3\",\"E\":\"4\"}\n",
    "invkeydictionary={0:\"A\",1:\"B\",2:\"C\",3:\"D\",4:\"E\"}\n",
    "outs = getAllKeys()\n",
    "keylist=outs[\"keylist\"]\n",
    "numberOfQuestions=outs[\"numberOfQuestions\"] \n",
    "numberOfVersions=len(keylist)\n",
    "numberOfStudents=df.shape[0]\n",
    "QIDs=createQuestionIDs(numberOfQuestions)\n",
    "headings=list(QIDs[0])#####headings=QIDs[0] assigns by reference, so changing headings will change QIDs[0]\n",
    "allAnswers_df = pd.DataFrame(columns = headings)# stores all student answers for each question, questions are the columns\n",
    "#results_df = pd.DataFrame(index=headings, columns = [\"A\",\"B\",\"C\",\"D\",\"E\",\"Skipped\",\"Diff\",\"Disc\"])\n",
    "headings.append(\"score\")\n",
    "analysis_df  = pd.DataFrame(columns = headings)# stores whether answer was correct, questions are the columns, last column is the score\n",
    "starttime = time.time()\n",
    "df=process_grades(keylist,df,numberOfQuestions, QIDs, analysis=True)\n",
    "number_correct_by_version=analyse_items(allAnswers_df, QIDs)\n",
    "endtime = time.time()\n",
    "print(\"That took: \"+str(endtime-starttime)+ \" sec\")\n",
    "\n",
    "# results_df=allAnswers1_df.apply(pd.Series.value_counts, axis=1).fillna(0)\n",
    "# if ' ' in list(results_df):\n",
    "#     results_df.rename(columns={' ': 'blank'}, inplace=True)\n",
    "# results_df=results_df.applymap(str)\n",
    "# results_df=addStarsToCorrectChoices(results_df,keylist)\n",
    "# results_df[\"Diff\"]=0\n",
    "# results_df[\"Discr\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grades and displays the N'th entry in the list using a keylist\n",
    "N=random.randint(1,df.shape[0]-1)\n",
    "\n",
    "check1=gradeWithKeylist(keylist, df.iat[N,2],numberOfQuestions, QIDs, analysis=False)\n",
    "print(\"Row \"+ str(N)+\": \"+df.iat[N,1]+\", \"+str(df.iat[N,0])+\". Missed \"+str(check1['missed'])+ \". Scored \"+str(check1['score'])+\"/\"+str(numberOfQuestions-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writing to csv\n",
    "df.to_csv(rawdatafilename+'_processed.csv')\n",
    "analysis_df.to_csv(rawdatafilename+'_analysis.csv')\n",
    "#### Don't opoen this file directly in excel, since the \"Answers\" column gets messed up. Import it using the import wizard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAnswers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(number_correct_by_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.loc[len(analysis_df)]=analysis_df.sum(axis=0)\n",
    "#analysis_df=analysis_df.drop(analysis_df.index[analysis_df.shape[0]-1])\n",
    "#analysis_df=analysis_df.drop(analysis_df.index[[4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_analysis_df=pd.DataFrame(columns = headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_analysis_df.loc[0,:]=analysis_df.loc[analysis_df.shape[0]-1,:].div(numberOfStudents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.shape[0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df=analysis_df.drop(analysis_df.index[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfStudents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_df.rename( index={'Difficulty':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_analysis_df.rename( index={0:'Difficulty'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
