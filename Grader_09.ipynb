{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports complete\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import os.path\n",
    "from os import remove\n",
    "import random\n",
    "from time import time\n",
    "import string\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "from fuzzywuzzy import process\n",
    "import glob\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "\n",
    "def text_between_subtrings(s, start, end):\n",
    "    return s.find(start), s.find(end)\n",
    "\n",
    "def wordify(question, max_words=30):\n",
    "    question_words=question.split()\n",
    "    if len(question_words)>max_words:\n",
    "        question_words=question_words[:max_words]\n",
    "    q=' '.join(question_words)\n",
    "    q=re.sub(' to power of ', '^', q)\n",
    "    q=re.sub('with subscript\\(\\(', '', q)\n",
    "    q=re.sub('\\)\\)', '', q)\n",
    "    q=re.sub('\\d+\\) _+', '', q)#these two lines get rid of any 3) _______ crap\n",
    "    q = re.sub('#\\)', '', q)\n",
    "    return q.strip()\n",
    "\n",
    "def wordify_answers(answer, max_words=30):\n",
    "    answer_words=answer.split()\n",
    "    if len(answer_words)>max_words:\n",
    "        answer_words=answer_words[:max_words]\n",
    "    q=' '.join(answer_words)\n",
    "    q=re.sub(' to power of ', '^', q)\n",
    "    if len(answer_words)>1:\n",
    "        q=re.sub('[\\bA-E]\\)', '', q)#strips the A) for all except the version question\n",
    "    return q.strip()\n",
    "\n",
    "def extract_questions(s, max_words=10):\n",
    "    more='yes'\n",
    "    n=1\n",
    "    questionlist=[]\n",
    "    while more=='yes':\n",
    "        start = '\\n'+str(n)\n",
    "        end = '\\n'+str(n+1)\n",
    "        p1, p2 = text_between_subtrings(s, start, end)\n",
    "        if p1!=-1 and p2!=-1:\n",
    "            txt=s[p1+len(start):p2]\n",
    "            ###Grab the part between ) and nA, and convert into words\n",
    "            pp1, pp2 = text_between_subtrings(txt, ')', '\\nA')\n",
    "            txt=txt[1:txt.find('\\nA')]\n",
    "            txt=wordify(txt,max_words)\n",
    "            questionlist.append(txt)\n",
    "            n+=1\n",
    "        elif p1!=-1 and p2==-1:\n",
    "            txt=s[p1+len(start):]\n",
    "            pp1, pp2 = text_between_subtrings(txt, ')', '\\nA')\n",
    "            txt=txt[1:txt.find('\\nA')]\n",
    "            txt=wordify(txt,max_words)\n",
    "            #re.sub('[^A-Z]', '', s)\n",
    "            questionlist.append(txt)\n",
    "            more='no'\n",
    "        else:\n",
    "            print(\"Sum ting wong. Shouldn't go here. p1= \"+str(p1)+\" p2= \"+str(p2))\n",
    "            more='no'\n",
    "    return questionlist\n",
    "    \n",
    "\n",
    "\n",
    "def createQuestionIDs_and_dfs(test_name=\"key\", max_words=30):\n",
    "#     set_trace()\n",
    "    All_IDs=[]\n",
    "    dfs=[]\n",
    "    for n in range(0,6):\n",
    "        filename=test_name+str(n)+\".txt\"\n",
    "        if (os.path.isfile(filename)):\n",
    "            with open(filename, encoding=\"utf-8\") as file:  \n",
    "                data = file.read()\n",
    "            p=data.rfind('\\n\\n\\n\\n1)')\n",
    "            if p!=-1: \n",
    "                questions=data[:p]\n",
    "            else:\n",
    "                print('Make sure questions and answers in key'+str(n)+' are separated by \\n\\n\\n\\n')\n",
    "                return []\n",
    "            if questions.find('version is this')==-1:\n",
    "                print('Make sure there is a version question with the words \"version is this\". ')\n",
    "                return []\n",
    "            \n",
    "            qids=extract_questions(questions, max_words)\n",
    "            qnum=len(qids)\n",
    "            np_qids=np.array(qids).reshape(qnum,1)\n",
    "            All_IDs.append(qids)\n",
    "            \n",
    "            \n",
    "            aa=extract_choices(questions, qnum)\n",
    "            np_aa=np.array(aa).reshape(qnum,len(aa[0]))\n",
    "            v1=np.concatenate((np_qids,np_aa),axis=1)\n",
    "            df=pd.DataFrame(v1,columns=[\"Question\",\"A\",\"B\",\"C\",\"D\",\"E\"],index=range(1,qnum+1))\n",
    "            df['Blank']=''\n",
    "            dfs.append(df)\n",
    "    \n",
    "    \n",
    "    '''The following makes sure that question IDs are mapped one-to-one. \n",
    "    This will fail if the different versions are not of the same test'''\n",
    "    for n in range(1,len(All_IDs)):\n",
    "        assert(len(set(All_IDs[n]))==len(All_IDs[0])),\"same question from v0 mapped to multiple questions in another version\"\n",
    "     \n",
    "    '''This part takes All_IDs which stores the full text of the questions and assigns the numbers \n",
    "    0....N to the questions of the first version. These numbers then become identifiers for each question. \n",
    "    Example: version 0: [what, when, how] and version 1: [how, when, what]. these will become [0, 1, 2] and\n",
    "    [2, 1, 0] respectively'''\n",
    "    qids_new=[]\n",
    "    qid_list=[x for x in range(0, qnum)]\n",
    "    qids_new.append(qid_list)\n",
    "    print(\"Generating QIDs. This might take a while..\")\n",
    "    starttime = time()\n",
    "    for whichlist in All_IDs[1:]:\n",
    "        qid_list=[1]*len(All_IDs[0])\n",
    "        for m in range(0,len(All_IDs[0])):\n",
    "            matching_question=process.extractOne(All_IDs[0][m], whichlist)[0]\n",
    "            qid_list[whichlist.index(matching_question)]=m\n",
    "        qids_new.append(qid_list)\n",
    "    endtime = time()\n",
    "    \n",
    "    print(\"Done. That took: \"+str(endtime-starttime)+ \" sec.\")\n",
    "    return {\"IDs\":qids_new, \"dfs\":dfs}        \n",
    "\n",
    "def extract_choices(s, qnum):\n",
    "    all_choices=[]\n",
    "    for n in range(1,qnum+1):\n",
    "        txt=''\n",
    "        start = '\\n'+str(n)\n",
    "        end = '\\n'+str(n+1)\n",
    "        p1, p2 = text_between_subtrings(s, start, end)\n",
    "        if p1!=-1 and p2!=-1:\n",
    "            txt=s[p1+len(start):p2]\n",
    "        if p1!=-1 and p2==-1:\n",
    "            txt=s[p1+len(start):]\n",
    "        anslist=[]\n",
    "        for m in range(0,4):\n",
    "            start=chr(65+m)+')'\n",
    "            end=chr(65+m+1)+')'\n",
    "            #looking for answer choices as the text between A) and B) for example\n",
    "            p1=txt.rfind(start)\n",
    "            p2=txt.rfind(end)\n",
    "            if p2!=-1:\n",
    "                ans=txt[p1:p2].strip()\n",
    "            else:\n",
    "                ans=txt[p1:].strip()\n",
    "            #if p2 was not found, do txt[p1:] rather than txt[p1:-1] which would truncate the last letter\n",
    "            ans=wordify_answers(ans)\n",
    "            if ans:\n",
    "                anslist.append(ans)\n",
    "            else:\n",
    "                anslist.append('')\n",
    "        if p2!=-1:\n",
    "            ans=txt[p2:].strip()\n",
    "            #ans=re.sub(' to power of ', '^', ans)\n",
    "            ans=wordify_answers(ans)\n",
    "            anslist.append(ans)\n",
    "        else:\n",
    "            anslist.append('')\n",
    "        all_choices.append(anslist)\n",
    "    return all_choices\n",
    "\n",
    "\n",
    "def letter_to_number (letter_list):\n",
    "    return [str(ord(x)-65) for x in letter_list]\n",
    "\n",
    "def getAllKeys(test_name = \"key\", fixed_points_per_question=1):\n",
    "    '''read all files named key0-key4, make them into strings and and return a dictionary\n",
    "    containing a list of keys and also the number of questions'''\n",
    "    keylist=[]\n",
    "    pointlist=[]\n",
    "#     set_trace()\n",
    "    for n in range(0,6):\n",
    "        filename=test_name + str(n)+\".txt\"\n",
    "        if (os.path.isfile(filename)):\n",
    "            with open(filename, encoding=\"utf-8\") as file: \n",
    "                data = file.read()\n",
    "            u=re.search('\\n\\n\\n\\n+1\\)',data)\n",
    "            if u is not None:\n",
    "                answers=data[u.start():].strip()\n",
    "            else:\n",
    "                print('Make sure questions and answers in key'+str(n)+' are separated by \\n\\n\\n\\n')\n",
    "                return None\n",
    "            ukey=re.findall(r'\\d\\)\\s(.*?)\\n+', answers)+re.findall(r'\\d\\)\\s(.*?)$', answers)\n",
    "            ukey=[x.split(', ') for x in ukey]\n",
    "            key=[letter_to_number(x) for x in ukey]\n",
    "            keylist.append(key)\n",
    "            \n",
    "            qnum=len(key)\n",
    "\n",
    "\n",
    "            points=[fixed_points_per_question]*qnum\n",
    "            \n",
    "            points[-1]=0\n",
    "            pointlist.append(points)\n",
    "    \n",
    "    assert(keylist), \"Answerkeys not found. Make sure they are named key0.txt, key1.txt etc\"\n",
    "    return {\"keylist\":keylist,\"pointlist\":pointlist,\"numberOfQuestions\":qnum}\n",
    "\n",
    "def make_exempt_question_list(freeqs, All_IDs):\n",
    "    '''freeqs is an array of question numbers in version 0 that should be given full credit.\n",
    "    Using the cross-reference table for questions between versions (All_IDs) this function\n",
    "    creates a dictionary which lists which questions are to be given full credit for each version\n",
    "    Example {0:[1,3], 1:[2,7]...} where [1,3] were the free questions in v0 and [2,7] are the same questions in v1'''\n",
    "    \n",
    "    \n",
    "    exempt_list={}\n",
    "\n",
    "    if not freeqs:\n",
    "        return exempt_list\n",
    "    \n",
    "    qnos = set(range(1,len(All_IDs[0])+1))\n",
    "    if not set(freeqs).issubset(qnos):\n",
    "        print(\"Make sure to enter valid question numbers for version0(A)\")\n",
    "        return exempt_list\n",
    "    else:\n",
    "        freeqids = [x-1 for x in freeqs]\n",
    "        for m in range(0,len(QIDs)):\n",
    "            exempt_list[m] = [QIDs[m].index(x) for x in freeqids]\n",
    "        return exempt_list\n",
    "\n",
    "    \n",
    "\n",
    "def process_grades(data,outs, QIDs,analysis=False,exempt_questions={}):\n",
    "    '''grades all exams using correct keys, writes questions missed and scores'''\n",
    "\n",
    "    for NN in range(0, data.shape[0]):\n",
    "        #print(\"NN: \"+str(NN))\n",
    "        ans=data.iat[NN,2]\n",
    "        #if len(ans)==numberOfQuestions-1:\n",
    "        if len(ans)==numberOfQuestions-1:\n",
    "            v=guess_the_version(ans, exempt_questions)\n",
    "            ans = ans+str(v)\n",
    "            print(\"Assuming version \"+chr(65+v)+ \" for: \"+data.iat[NN,1]+\" (Srl No: \"+data.iat[NN,0]+\").Last entry was missing\" )\n",
    "        if ans[-1]==\" \":\n",
    "            v=guess_the_version(ans, exempt_questions)\n",
    "            ans = ans[:-1]+str(v)\n",
    "            print(\"Assuming version \"+chr(65+v)+ \" for: \"+data.iat[NN,1]+\" (Srl No: \"+data.iat[NN,0]+\").Last entry was a space\")\n",
    "        assert len(QIDs[0])==len(ans), \"Failing for item {}, key = {}, ans = {}\".format(NN, key, ans)\n",
    "        check1=gradeWithKeylist(ans, outs, QIDs, analysis, NN, exempt_questions)\n",
    "        data.iat[NN,2]=ans\n",
    "        data.iat[NN,3]=check1['missed']\n",
    "        data.iat[NN,4]=check1['score']\n",
    "        data.iat[NN,5]=100.0*float(check1['score'])/float(new_totalpoints)\n",
    "\n",
    "    if analysis:\n",
    "        #remove the column with the version numbers\n",
    "        analysis_df.drop(analysis_df.columns[analysis_df.shape[1]-2], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def gradeWithKeylist(ans,outs, QIDs, analysis=False, N=0, exempt_questions={}):\n",
    "    '''multiple versions - find the correct key as indicated on the last question on the exam \n",
    "    exempt_questions is a dictionary that says which questions are free (i.e. full points) for each version'''\n",
    "    \n",
    "    keylist=outs[\"keylist\"]\n",
    "    pointlist=outs[\"pointlist\"]\n",
    "    numberOfQuestions=outs[\"numberOfQuestions\"] \n",
    "    \n",
    "    assert(keylist!=[])\n",
    "    assert (ans[-1:] in ['0','1','2','3','4'])\n",
    "    whichKey=int(ans[-1:])\n",
    "    \n",
    "    key=keylist[whichKey]\n",
    "    points=pointlist[whichKey]\n",
    "    assert len(key)==len(ans), \"Failing for item {}, key = {}, ans = {}\".format(N, key, ans)\n",
    "    missed=\"\"\n",
    "    rejalt=[1]*numberOfQuestions\n",
    "    if not exempt_questions:\n",
    "        for n in range(0,len(key)-1):\n",
    "            if not set(ans[n]).issubset(key[n]):\n",
    "                ####If there are multiple correct answers to a question, then this allows for ANY subset of the correct choice getting full credit. \n",
    "                #### full credit. No credit for a correct  Use the == operator to give credit only when all correct choices have been picked. \n",
    "                missed+=str(n+1)+\", \"\n",
    "                rejalt[n]=0\n",
    "    else:\n",
    "        for n in range(0,len(key)-1):\n",
    "            if not ans[n] in key[n] and n not in exempt_questions[whichKey]:\n",
    "                missed+=str(n+1)+\", \"\n",
    "                rejalt[n]=0\n",
    "    if sum(rejalt)==numberOfQuestions:\n",
    "        missed=\"v\"+chr(65+whichKey)+\": \"+\"ALL CORRECT\"\n",
    "    else:\n",
    "        missed=\"v\"+chr(65+whichKey)+\": \"+missed[:len(missed)-2]\n",
    "    score=sum([i*j for i,j in zip(points,rejalt)])\n",
    "    \n",
    "\n",
    "    mydict1 = dict(zip(QIDs[whichKey],rejalt))\n",
    "    #sortedIDs=sorted(mydict1.keys())\n",
    "    sorted_rejalt=[mydict1[k] for k in QIDs[0]]####its sorted according to v0\n",
    "    \n",
    "\n",
    "    \n",
    "    if analysis:   \n",
    "        sorted_rejalt.append(score)\n",
    "        analysis_df.loc[N] = sorted_rejalt \n",
    "    \n",
    "      \n",
    "    return {'missed':missed, 'score':score}\n",
    "\n",
    "\n",
    "def guess_the_version(no_version, exempt={}):\n",
    "#     set_trace()\n",
    "    scores=[]\n",
    "    assert len(no_version) in [numberOfQuestions-1, numberOfQuestions]\n",
    "    #last digit was a space so the last digit will be overwritten\n",
    "    if len(no_version) == numberOfQuestions:\n",
    "        try_version = no_version[:-1]\n",
    "    #last digit was missing so the last digit will be added\n",
    "    else:\n",
    "        try_version = no_version\n",
    "    for n in range(numberOfVersions):\n",
    "        check1=gradeWithKeylist(try_version+str(n), outs, QIDs, analysis=False, exempt_questions=exempt)\n",
    "        scores.append(check1['score'])\n",
    "    return scores.index(max(scores))\n",
    "\n",
    "\n",
    "\n",
    "def make_into_percent(adf):\n",
    "    '''Takes a dataframe and converts into np array to perform math operations.\n",
    "    In this case it divides each element by the sum of the row and times by 100 to make it a percent.'''\n",
    "    cols=list(adf)\n",
    "    #adf=adf.applymap(float)\n",
    "    np_df=adf.values\n",
    "    np_df=100*np_df/np.sum(np_df, axis=1, keepdims=True)\n",
    "    return pd.DataFrame(np_df,columns=cols)\n",
    "\n",
    "\n",
    "def mark_correct_answers(pardf,n,keylist):\n",
    "    \n",
    "    key_to_use=keylist[n]\n",
    "    for m in range(0,pardf.shape[0]):\n",
    "        if len(key_to_use[m])==1:\n",
    "            cor=int(key_to_use[m][0])\n",
    "            pardf.iloc[m,cor]='[Correct] '+pardf.iloc[m,cor]\n",
    "        else:\n",
    "            cor_list=[int(x) for x in key_to_use[m]]\n",
    "            for cor in cor_list:\n",
    "                pardf.iloc[m,cor]='[Correct] '+pardf.iloc[m,cor]\n",
    "                \n",
    "    return pardf\n",
    "\n",
    "\n",
    "\n",
    "def analyse_items(df, koschen_paper, keylist):\n",
    "    '''create separate dfs with how many marked correct for each version separately'''\n",
    "\n",
    "    outvars=[]\n",
    "    versionsfound=[]\n",
    "    students_in_this_version=[]\n",
    "    \n",
    "    just_answers_df=df.loc[:,\"Answers\"]\n",
    "    just_answers_df=just_answers_df.apply(str)\n",
    "    just_answers_df=just_answers_df.apply(lambda x: x.replace(' ', 'b'))\n",
    "    just_answers_df=just_answers_df.apply(lambda x: ' '.join(list(x)))\n",
    "    just_answers_df=just_answers_df.str.split(' ', expand=True)\n",
    "\n",
    "    for n in range(0,len(koschen_paper)):\n",
    "        ##get answers for version n\n",
    "        part_df = just_answers_df.loc[just_answers_df[list(just_answers_df)[-1]] == str(n)]\n",
    "        if not part_df.empty:\n",
    "            print(\"Analysing data for version: \"+chr(n+65))\n",
    "            part_df = part_df.T\n",
    "            part_df = part_df.apply(pd.Series.value_counts, axis = 1).fillna(0)\n",
    "            if 'b' in list(part_df):\n",
    "                part_df.rename(columns = {'b': 'Blank'}, inplace = True)\n",
    "            vers = list(part_df)\n",
    "            if 'Blank' in vers: \n",
    "                vers.remove('Blank')\n",
    "            lvers = [chr(int(x)+65) for x in vers]\n",
    "            part_df.rename(columns = dict(zip(vers,lvers)), inplace=True)\n",
    "            num_students_this_version = part_df.iloc[0,:].sum()\n",
    "            part_df = make_into_percent(part_df)\n",
    "            part_df = part_df.applymap('{:,.0f}%'.format)\n",
    "            if not 'Blank' in list(part_df):\n",
    "                part_df['Blank']=''\n",
    "            question_list = list(koschen_paper[n].loc[:,\"Question\"])\n",
    "            part_df.index = question_list\n",
    "            kp = koschen_paper[n].copy()\n",
    "            kp.set_index(\"Question\", inplace = True)\n",
    "            kp.index.name = None ###This prevents an extra fictitious row from showing up in the header row\n",
    "\n",
    "            part_df = kp+\"<<\"+part_df+\">>\"\n",
    "            part_df = part_df.applymap(lambda m: re.sub('<<0%>>', '', m) )\n",
    "            part_df = part_df.applymap(lambda m: re.sub('<<>>', '', m) )\n",
    "            part_df = mark_correct_answers(part_df,n,keylist)\n",
    "\n",
    "            outvars.append(part_df)\n",
    "            versionsfound.append(lvers[n])\n",
    "            students_in_this_version.append(num_students_this_version)\n",
    "    \n",
    "    \n",
    "#     Return two dict so that the html function knows which version each table belongs to, and how many students took that version    \n",
    "    return dict(zip(versionsfound,outvars)), dict(zip(versionsfound,students_in_this_version))\n",
    "\n",
    "    \n",
    "def make_item_analysis(a_df, qlist):\n",
    "    \n",
    "    item_analysis_df=pd.DataFrame(index=[\"Difficulty\",\"Discrimination\"],columns = list(analysis_df))\n",
    "    n=a_df.shape[0]\n",
    "    v=analysis_df.values#converts into np array\n",
    "    \n",
    "    \n",
    "    #Calculating Difficulty\n",
    "    u1=np.sum(v,axis=0)/n\n",
    "    item_analysis_df.loc[\"Difficulty\"]=u1[0:u1.shape[0]]\n",
    "    \n",
    "    #Calculating Discrimination\n",
    "    students_per_group=n//3\n",
    "    if students_per_group<2:\n",
    "        print(\"Need more students for discrimination analysis (at least 7).\")\n",
    "        return item_analysis_df\n",
    "    else:\n",
    "        v=v[0:v.shape[0]-1,:]#exclude the bottom row which had the sums (total number correct for each q)\n",
    "        v=v[v[:,v.shape[1]-1].argsort()[::-1]]#sort descending by scores\n",
    "        #print(v)\n",
    "        u1=np.sum(v[0:students_per_group,:],axis=0)#top scorers\n",
    "        u2=np.sum(v[n-students_per_group-1 : n,:],axis=0)#bottom scorers\n",
    "        disc=(u1-u2)/students_per_group\n",
    "        disc.shape\n",
    "        item_analysis_df.loc[\"Discrimination\"]=disc[0:disc.shape[0]]\n",
    "    \n",
    "    item_analysis_df.drop(\"score\", axis=1, inplace=True)\n",
    "    item_analysis_df = item_analysis_df.T\n",
    "    item_analysis_df.index = qlist[:-1]\n",
    "    \n",
    "    return item_analysis_df\n",
    "    \n",
    "\n",
    "#################Writing data#############################\n",
    "def write_to_xl(adf, rfilename):\n",
    "    adf.rename(columns={'Srl No': 'Serial Number Text Grade <Text>'})#This facilitates the Vlookup later\n",
    "    writer = pd.ExcelWriter(rfilename+'_processed.xlsx')\n",
    "    adf.to_excel(writer,'Sheet1',index=False)\n",
    "    writer.save()\n",
    "    \n",
    "def write_to_csv(adf, rfilename):\n",
    "    adf.drop(\"Answers\", axis=1, inplace=True)\n",
    "    filename = rfilename+'_processed.csv'\n",
    "    #adf=adf.rename(columns={'Srl No': 'Serial Number Text Grade <Text>'})#This facilitates the Vlookup later\n",
    "    adf.to_csv(filename, index=False)\n",
    "    \n",
    "\n",
    "def write_to_webpage(j_df, ia_df, pointdrop, ncbv={}, sbv={}, list_of_free_qs=[], histobin=11):\n",
    "    filename = rawdatafilename+'_summary.html'\n",
    "    f = open(filename,'w',encoding='utf8')\n",
    "    \n",
    "    max_score=max(j_df['Score'])\n",
    "    number_of_maxes=len([x for x in j_df['Score'] if x==max_score])\n",
    "    \n",
    "    uu=j_df['Percentage'].describe().to_frame()\n",
    "    uu.rename(columns={'Percentage': \"Value\"}, index={'count':'Number of Students','mean':'Mean(%)', 'std':'Standard Deviation', 'min':'Lowest(%)','25%':'25th percentile', '50%':'50th percentile', '75%':'75th percentile', 'max':\"Highest(%)\"},inplace=True)\n",
    "    uu.loc['Maximum Available(%) '] = [100*totalpoints/new_totalpoints]\n",
    "    uu.loc['Number of Top Scorers'] = number_of_maxes\n",
    "    uu.loc['Points dropped '] = pointdrop\n",
    "    if freebies:\n",
    "        uu.loc['Free Questions '] = len(list_of_free_qs)\n",
    "        \n",
    "\n",
    "    pre=\"<h2>Summary Data:</h2>\"\n",
    "    summary_table=uu.to_html(float_format=lambda x: '%10.2f' % x).replace(\"dataframe\" ,\"sumdat\")\n",
    "    summary_table=pre+summary_table\n",
    "    post=\"<p>Score Distribution:</p>\"\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    df['Percentage'].plot(kind='hist', bins=10)\n",
    "    plt.xlim(right=100*totalpoints/new_totalpoints)\n",
    "    figure.savefig('histo.svg')\n",
    "    \n",
    "    pre=\"<h2>Score Distribution:</h2>\"\n",
    "    image_code='<img src=\"histo.svg\" alt=\"histogram\">'\n",
    "    image=pre+image_code\n",
    "\n",
    "    pre=\"<h2>Item Analysis:</h2>\"\n",
    "    item_analysis_table=ia_df.sort_values('Difficulty').to_html(float_format=lambda x: '%10.2f' % x).replace(\"dataframe\" ,\"customers\")\n",
    "    item_analysis_table=pre+item_analysis_table\n",
    "\n",
    "    missed_tables=\"\"\n",
    "    if ncbv:\n",
    "        for ver in ['A', 'B','C','D','E']:\n",
    "            if ver in ncbv.keys():\n",
    "                if sbv:\n",
    "                    nn=str(int(sbv[ver]))\n",
    "                    pre=\"<h2>Distractor Analysis for Version \"+ver+\": (\"+nn+\" Students) </h2>\"\n",
    "                else:\n",
    "                    pre=\"<h2>Distractor Analysis for Version \"+ver+\":</h2>\"\n",
    "                post=ncbv[ver].to_html()\n",
    "                post=post.replace(\"dataframe\" ,\"howmany\")\n",
    "                post=post.replace('<td>[Correct]','<td class=\"correct\">')\n",
    "#                 post=post.replace('&lt;:','<span class=\"answered_by\">')\n",
    "#                 post=post.replace(':&gt;','</span>')\n",
    "                post=re.sub('&lt;&lt;','<span class=\"answered_by\">',post)\n",
    "                post=re.sub('&gt;&gt;','</span>',post)\n",
    "                missed_tables+=pre+post\n",
    "\n",
    "    ##insert a script to make the webpage latex compatible. Edit the final  html file as \\( \\latex\\code \\)\n",
    "    html_start = \"\"\"<html>\n",
    "    <head>\n",
    "     <link rel=\"stylesheet\" type=\"text/css\" href=\"mystyle.css\">\n",
    "    <script type=\"text/javascript\" async\n",
    "    src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML\" async>\n",
    "    </script>\n",
    "    </head>\n",
    "    <body>\n",
    "    <h1>Data Analysis</h1>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    html_end='''</body>\n",
    "    </html>'''\n",
    "    message=html_start+summary_table+image+item_analysis_table+missed_tables+html_end\n",
    "    f.write(message)\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "    #Change path to reflect file location\n",
    "    webbrowser.open_new_tab(filename)\n",
    "\n",
    "###############################################\n",
    "\n",
    "############### Checking for incorrect Srl Nos################\n",
    "\n",
    "\n",
    "def check_serial_numbers(gradebook,datafile):\n",
    "    df=pd.read_csv(gradebook, usecols=[\"Last Name\", \"First Name\", \"Serial Number Text Grade <Text>\"])\n",
    "    df_all=pd.read_excel(datafile, header=None, usecols=[0,1],names = [\"Serial Number Text Grade <Text>\", \"Name\"])\n",
    "\n",
    "    checker_left = pd.merge(df,df_all[['Serial Number Text Grade <Text>','Name']],on='Serial Number Text Grade <Text>', how='left')\n",
    "    checker_right = pd.merge(df,df_all[['Serial Number Text Grade <Text>','Name']],on='Serial Number Text Grade <Text>', how='right')\n",
    "    u1=checker_left[checker_left.isnull().any(axis=1)]\n",
    "    u2=checker_left[checker_left['Serial Number Text Grade <Text>'].duplicated(keep=False)]\n",
    "    u3=checker_right[checker_right.isnull().any(axis=1)]\n",
    "    error_rpt=pd.concat([u1, u2, u3], axis=0)\n",
    "    error_rpt[\"Last Name\"] = error_rpt[\"Last Name\"]+' '+error_rpt['First Name']\n",
    "    error_rpt.drop('First Name', axis=1,inplace=True)\n",
    "    error_rpt.rename(columns={'Serial Number Text Grade <Text>': 'Srl No', 'Last Name':'Registered Name', 'Name':'Entered Name'}, inplace=True) \n",
    "    return error_rpt\n",
    "\n",
    "################ Trash fakes #############\n",
    "def trash_files(filename_to_remove):\n",
    "    fakes = glob.glob(filename_to_remove)\n",
    "    if fakes:\n",
    "        for file in fakes:\n",
    "            os.remove(file)\n",
    "            print(\"{} removed\".format(file))\n",
    "        print(\"All {} Removed!\".format(filename_to_remove))\n",
    "\n",
    "print(\"All imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually convert the dat file into an excel file using excel. Only extract the serial number,\n",
    "name and Answers, and make sure Answers is text.\n",
    "**Serial number should not be text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from All_fakes.xlsx\n"
     ]
    }
   ],
   "source": [
    "#COLLECTING DATA\n",
    "## The code will calculate automatically whether to use All or All_fakes (It will use All_fakes only if All if not available. \n",
    "## Use the following lines only to over-ride this)\n",
    "# rawdatafilename='All'\n",
    "# datafilename=rawdatafilename+'.xlsx'\n",
    "\n",
    "rawdatafilename = ''\n",
    "if os.path.exists(\"All.xlsx\"):\n",
    "    rawdatafilename='All'\n",
    "    datafilename=rawdatafilename+'.xlsx'\n",
    "    trash_files('*fake*')\n",
    "\n",
    "if os.path.exists(\"All_fakes.xlsx\"):\n",
    "    rawdatafilename='All_fakes'\n",
    "    datafilename=rawdatafilename+'.xlsx'\n",
    "\n",
    "assert rawdatafilename, \"Make sure either All or All_fakes is ready\"\n",
    "print(\"Using data from {}.xlsx\".format(rawdatafilename))\n",
    "\n",
    "\n",
    "gradebook='BSGrades.csv'\n",
    "assert(os.path.isfile(datafilename)),'Make sure '+datafilename+\" is ready\"\n",
    "assert(os.path.isfile(gradebook)),'Make sure '+gradebook+' is ready'\n",
    "\n",
    "df = pd.read_excel(datafilename, header=None, usecols=[0,1,2], names = [\"Srl No\", \"Name\", \"Answers\"], dtype='str')\n",
    "#parse_cols makes sure that only cols 0,1 and 2 are extracted\n",
    "just_answers_df=df.loc[:,\"Answers\"]\n",
    "#checking for blanks, print only if blanks found\n",
    "asterisks = False\n",
    "blankers=df[df['Answers'].str.contains(\" \")]\n",
    "stars = df[df['Answers'].str.contains('\\*')]\n",
    "if not blankers.empty:\n",
    "    print(\"The following scantrons had blanks in them. Please resolve before proceeding.\")\n",
    "    display(blankers)\n",
    "if not stars.empty:\n",
    "    print(\"The following scantrons were flagged as unclear. Please resolve before proceeding.\")\n",
    "    display(stars)\n",
    "    asterisks = True\n",
    "ER=check_serial_numbers(gradebook,datafilename)\n",
    "if not ER.empty:\n",
    "    display(ER)\n",
    "\n",
    "df[\"Missed\"] = \"\"\n",
    "df[\"Score\"]=0\n",
    "df[\"Percentage\"]=np.nan\n",
    "number_of_questions_from_scantrons=len(df.loc[0,\"Answers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grading out of total - 3 since this is the final.\n",
      "Assuming answerkey files are in the .txt files named 2019final_v\n",
      "Generating QIDs. This might take a while..\n",
      "Done. That took: 3.627302885055542 sec.\n"
     ]
    }
   ],
   "source": [
    "assert not asterisks, \"Please resolve the answerkeys with *'s in them before proceeding'\"\n",
    "\n",
    "\n",
    "#initializing everything\n",
    "points_per_question=3\n",
    "\n",
    "#determining whether the test in question is a final or a midterm. 3 points dropped for a final and 2 points dropped for a midterm\n",
    "tstfiles=glob.glob(\"*.tst\")\n",
    "tstname = tstfiles[0][:-5]\n",
    " \n",
    "if bool([x for x in tstfiles if \"final\" in x.lower()]):\n",
    "    point_drop = 3\n",
    "    print(\"Grading out of total - 3 since this is the final.\")\n",
    "else:\n",
    "    point_drop = 2\n",
    "    print(\"Grading out of total - 2 since this is a midterm.\")\n",
    "\n",
    "\n",
    "assert os.path.exists(tstname+\"0.txt\") |  os.path.exists(\"key0.txt\"), \"answerkey0 not found. Make sure it is named key0.txt or something like 2019_test1v0.txt\"\n",
    "  \n",
    "if not os.path.exists(tstname+\"0.txt\"):\n",
    "        tstname = \"key\"\n",
    "print(\"Assuming answerkey files are in the .txt files named {}\".format(tstname))      \n",
    "    \n",
    "freebies=[]#enter ACTUAL QUESTION NUMBER of questions from version 0(A) to which to award full credit regardless of response\n",
    "if freebies:\n",
    "    print(\"Some questions are being awarded free points!\".upper())\n",
    "\n",
    "\n",
    "outs = getAllKeys(tstname, points_per_question)\n",
    "keylist=outs[\"keylist\"]\n",
    "pointlist=outs[\"pointlist\"]\n",
    "numberOfQuestions=outs[\"numberOfQuestions\"]\n",
    "assert number_of_questions_from_scantrons == numberOfQuestions, \"The number of questions on the test ({}) does not match the number of questions on the scantron ({})\".format(numberOfQuestions,number_of_questions_from_scantrons)\n",
    "totalpoints=sum(pointlist[2])\n",
    "new_totalpoints=totalpoints-point_drop\n",
    "numberOfVersions=len(keylist)\n",
    "numberOfStudents=df.shape[0]\n",
    "quids_dfs=createQuestionIDs_and_dfs(tstname, max_words=50)\n",
    "QIDs=quids_dfs[\"IDs\"]\n",
    "koschen_paper=quids_dfs['dfs']\n",
    "v0_question_list = list(koschen_paper[0].loc[:,\"Question\"]) #List of questions in version 0\n",
    "assert(keylist and pointlist and QIDs and koschen_paper and numberOfQuestions!=0),\"Either keylist or pointlist or QIDs or koschen_paper or  numberOfQuestions is null\"\n",
    "\n",
    "\n",
    "analysis_df  = pd.DataFrame(index=range(numberOfStudents),columns = list(QIDs[0])+[\"score\"])# stores whether answer was correct, questions are the columns, last column is the score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting calculations...\n",
      "Analysing data for version: A\n",
      "Analysing data for version: B\n",
      "Analysing data for version: C\n",
      "Analysing data for version: D\n",
      "Done. That took: 0.339092493057251 sec for 19 students\n"
     ]
    }
   ],
   "source": [
    "##Everything initialized. Running the code now\n",
    "# too_few_answers =  df[df['Answers'].map(len)<numberOfQuestions-1]\n",
    "# too_many_answers =  df[df['Answers'].map(len)>numberOfQuestions]\n",
    "# stranges = [too_few_answers, too_many_answers]\n",
    "# too_many_or_too_few = False\n",
    "# for strange in stranges:\n",
    "#     if not strange.empty:\n",
    "#         display(strange[['Srl No', 'Name','Answers']])\n",
    "#         too_many_or_too_few = True\n",
    "# assert not too_many_or_too_few, \"Check that all answer strings have correct length\"   \n",
    "\n",
    "incorrect_length =  df[(df['Answers'].map(len)<numberOfQuestions-1) | (df['Answers'].map(len)>numberOfQuestions)]\n",
    "if not incorrect_length.empty:\n",
    "    incorrect_length=incorrect_length[['Srl No', 'Name','Answers']]\n",
    "    print(\"The following students had too many or too few answers\")\n",
    "    display(incorrect_length)\n",
    "assert incorrect_length.empty, \"Check that all answer strings have correct length\" \n",
    "\n",
    "last_entry_missing=df[df['Answers'].map(len)==numberOfQuestions-1]\n",
    "if not last_entry_missing.empty:\n",
    "    last_entry_missing=last_entry_missing[['Srl No', 'Name','Answers']]\n",
    "    print(\"The following students had no entry for the version question\")\n",
    "    display(last_entry_missing)\n",
    "last_entry_space = df[(df['Answers'].str[-1] == ' ') & (df['Answers'].map(len) == numberOfQuestions)]\n",
    "if not last_entry_space.empty:\n",
    "    last_entry_space=last_entry_space[['Srl No', 'Name','Answers']]\n",
    "    print(\"The following students had a blank entered for version question\")\n",
    "    display(last_entry_space)\n",
    "\n",
    "print(\"Starting calculations...\")\n",
    "starttime = time()\n",
    "exempts=make_exempt_question_list(freebies, QIDs)\n",
    "df=process_grades(df,outs, QIDs, analysis=True,exempt_questions=exempts )\n",
    "number_correct_by_version, students_by_version = analyse_items(df, koschen_paper,keylist)\n",
    "item_analysis_df = make_item_analysis(analysis_df, v0_question_list) \n",
    "endtime = time()\n",
    "print(\"Done. That took: \"+str(endtime-starttime)+ \" sec for \"+str(numberOfStudents)+\" students\")\n",
    "#check for duplicated serial numbers\n",
    "dupes=df[df['Srl No'].duplicated(keep=False)]\n",
    "if not dupes.empty:\n",
    "    print('Warning: Duplicates in serial numbers found!')\n",
    "    display(dupes)    \n",
    "max_score=analysis_df.at[analysis_df['score'].idxmax(),'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_to_csv(df.sort_values('Score', ascending=False),rawdatafilename)\n",
    "if (os.path.isfile('mystyle.css')):\n",
    "    write_to_webpage(df, item_analysis_df, point_drop, number_correct_by_version, students_by_version, list_of_free_qs=freebies)\n",
    "else:\n",
    "    print(\"Copy the css file over first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grades and displays the N'th entry in the list using a keylist\n",
    "#N=random.randint(1,df.shape[0]-1)\n",
    "#for N in range(df.shape[0]-1):\n",
    "N=5\n",
    "exempts=make_exempt_question_list(freebies, QIDs)\n",
    "check1=gradeWithKeylist(df.iat[N,2], outs, QIDs, analysis=False, exempt_questions=exempts)\n",
    "print(\"Row \"+ str(N)+\": \"+df.iat[N,1]+\", \"+str(df.iat[N,0])+\". Missed \"+str(check1['missed'])+ \". Scored \"+str(check1['score'])+\"/\"+str(totalpoints))\n",
    "print('That is: '+str(100*check1['score']/new_totalpoints)+'% with '+str(point_drop)+' points dropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[N,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEVELOPMENT AREA\n",
    "## All code below is in development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_answers_df=df.loc[:,\"Answers\"]\n",
    "just_answers_df=just_answers_df.apply(str)\n",
    "just_answers_df=just_answers_df.apply(lambda x: x.replace(' ', 'b'))\n",
    "just_answers_df=just_answers_df.apply(lambda x: ' '.join(list(x)))\n",
    "just_answers_df=just_answers_df.str.split(' ', expand=True)\n",
    "\n",
    "n = 2\n",
    "#just_answers_df.sort_values(list(just_answers_df)[-1])\n",
    "part_df = just_answers_df.loc[just_answers_df[list(just_answers_df)[-1]] == str(n)]\n",
    "if not part_df.empty:\n",
    "    print(\"Analysing data for version: \"+chr(n+65))\n",
    "    part_df = part_df.T\n",
    "    part_df = part_df.apply(pd.Series.value_counts, axis = 1).fillna(0)\n",
    "    if 'b' in list(part_df):\n",
    "        part_df.rename(columns = {'b': 'Blank'}, inplace = True)\n",
    "    vers = list(part_df)\n",
    "    if 'Blank' in vers: \n",
    "        vers.remove('Blank')\n",
    "    lvers = [chr(int(x)+65) for x in vers]\n",
    "    part_df.rename(columns = dict(zip(vers,lvers)), inplace=True)\n",
    "    num_students_this_version = part_df.iloc[0,:].sum()\n",
    "    part_df = make_into_percent(part_df)\n",
    "    part_df = part_df.applymap('{:,.0f}%'.format)\n",
    "    if not 'Blank' in list(part_df):\n",
    "        part_df['Blank']=''\n",
    "    question_list = list(koschen_paper[n].loc[:,\"Question\"])\n",
    "    part_df.index = question_list\n",
    "    kp = koschen_paper[n].copy()\n",
    "    kp.set_index(\"Question\", inplace = True)\n",
    "    kp.index.name = None ###This prevents an extra fictitious row from showing up in the header row\n",
    "\n",
    "    part_df = kp+\"<\"+part_df+\">\"\n",
    "    part_df = part_df.applymap(lambda m: re.sub('<0%>', '', m) )\n",
    "    part_df = part_df.applymap(lambda m: re.sub('<>', '', m) )\n",
    "    part_df = mark_correct_answers(part_df,n,keylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_items(df, koschen_paper, keylist):\n",
    "    '''create separate dfs with how many marked correct for each version separately'''\n",
    "\n",
    "    outvars=[]\n",
    "    versionsfound=[]\n",
    "    students_in_this_version=[]\n",
    "    \n",
    "    just_answers_df=df.loc[:,\"Answers\"]\n",
    "    just_answers_df=just_answers_df.apply(str)\n",
    "    just_answers_df=just_answers_df.apply(lambda x: x.replace(' ', 'b'))\n",
    "    just_answers_df=just_answers_df.apply(lambda x: ' '.join(list(x)))\n",
    "    just_answers_df=just_answers_df.str.split(' ', expand=True)\n",
    "\n",
    "    for n in range(0,len(koschen_paper)):\n",
    "        ##get answers for version n\n",
    "        part_df = just_answers_df.loc[just_answers_df[list(just_answers_df)[-1]] == str(n)]\n",
    "        if not part_df.empty:\n",
    "            print(\"Analysing data for version: \"+chr(n+65))\n",
    "            part_df = part_df.T\n",
    "            part_df = part_df.apply(pd.Series.value_counts, axis = 1).fillna(0)\n",
    "            if 'b' in list(part_df):\n",
    "                part_df.rename(columns = {'b': 'Blank'}, inplace = True)\n",
    "            vers = list(part_df)[:-1]\n",
    "            lvers = [chr(int(x)+65) for x in vers]\n",
    "            part_df.rename(columns = dict(zip(vers,lvers)), inplace=True)\n",
    "            num_students_this_version = int(part_df.iloc[0,:].sum())\n",
    "            part_df = make_into_percent(part_df)\n",
    "            part_df = part_df.applymap('{:,.0f}%'.format)\n",
    "            question_list = list(koschen_paper[n].loc[:,\"Question\"])\n",
    "            part_df.index = question_list\n",
    "            kp = koschen_paper[n].copy()\n",
    "            kp.set_index(\"Question\", inplace = True)\n",
    "            kp.index.name = None ###This prevents an extra fictitious row from showing up in the header row\n",
    "            part_df = kp+\"<\"+part_df+\">\"\n",
    "            part_df = part_df.applymap(lambda m: re.sub('<0%>', '', m) )\n",
    "            part_df = mark_correct_answers(part_df,n,keylist)\n",
    "            \n",
    "            outvars.append(part_df)\n",
    "            versionsfound.append(lvers[n])\n",
    "            students_in_this_version.append(num_students_this_version)\n",
    "    \n",
    "    \n",
    "#     Return two dict so that the html function knows which version each table belongs to, and how many students took that version    \n",
    "    return dict(zip(versionsfound,outvars)), dict(zip(versionsfound,students_in_this_version))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "filename=\"key\"+str(n)+\".txt\"\n",
    "if (os.path.isfile(filename)):\n",
    "    with open(filename, encoding=\"utf-8\") as file: \n",
    "        data = file.read()\n",
    "    u=re.search('\\n\\n\\n\\n+1\\)',data)\n",
    "#     answers=data[u.start():].strip()    \n",
    "#     ukey=re.findall(r'\\d\\)\\s(.*?)\\n+', answers)+re.findall(r'\\d\\)\\s(.*?)$', answers)\n",
    "#     ukey=[x.split(', ') for x in uu]\n",
    "#     key=[letter_to_number(x) for x in ukey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=data[:u.start()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs=re.findall(r'\\n\\n\\d\\)(.*?)\\n\\n\\d\\)', questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " uu=re.findall(r'\\d\\)\\s(.*?)\\n+', answers)+re.findall(r'\\d\\)\\s(.*?)$', answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x+1 if x >= 45 else x+5 for x in l]\n",
    "ukey=[x.split(', ') for x in uu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_to_number (letter_list):\n",
    "    return [str(ord(x)-65) for x in letter_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_to_number(['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukey=[letter_to_number(x) for x in ukey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m='4'\n",
    "m in ukey[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs=getAllKeys(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keylist=outs['keylist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradeWithKeylist(ans,outs, QIDs, analysis=False, N=0, exempt_questions={}):\n",
    "    '''multiple versions - find the correct key as indicated on the last question on the exam \n",
    "    exempt_questions is a dictionary that says which questions are free (i.e. full points) for each version'''\n",
    "    \n",
    "    keylist=outs[\"keylist\"]\n",
    "    pointlist=outs[\"pointlist\"]\n",
    "    numberOfQuestions=outs[\"numberOfQuestions\"] \n",
    "    \n",
    "    assert(keylist!=[])\n",
    "    assert (ans[-1:] in ['0','1','2','3','4'])\n",
    "    whichKey=int(ans[-1:])\n",
    "    \n",
    "    key=keylist[whichKey]\n",
    "    points=pointlist[whichKey]\n",
    "    assert len(key)==len(ans)\n",
    "    missed=\"\"\n",
    "    rejalt=[1]*numberOfQuestions\n",
    "    if not exempt_questions:\n",
    "        for n in range(0,len(key)-1):\n",
    "            if not ans[n] in key[n]:\n",
    "                missed+=str(n+1)+\", \"\n",
    "                rejalt[n]=0\n",
    "    else:\n",
    "        for n in range(0,len(key)-1):\n",
    "            if not ans[n] in key[n] and n not in exempt_questions[whichKey]:\n",
    "                missed+=str(n+1)+\", \"\n",
    "                rejalt[n]=0\n",
    "    if sum(rejalt)==numberOfQuestions:\n",
    "        missed=\"v\"+chr(65+whichKey)+\": \"+\"ALL CORRECT\"\n",
    "    else:\n",
    "        missed=\"v\"+chr(65+whichKey)+\": \"+missed[:len(missed)-2]\n",
    "    score=sum([i*j for i,j in zip(points,rejalt)])\n",
    "\n",
    "    mydict1 = dict(zip(QIDs[whichKey],rejalt))\n",
    "    print(\"whichKey: \"+str(whichKey))\n",
    "    print(\"rejalt: \"+str(rejalt))\n",
    "    print(\"QIDs[whichKey]: \"+str(QIDs[whichKey]))\n",
    "    print(\"mydict1= :\"+str(mydict1))\n",
    "    print(\"QIDs[0]: \"+str(QIDs[0]))\n",
    "    sorted_rejalt=[mydict1[k] for k in QIDs[0]]####its sorted according to v0\n",
    "    \n",
    "\n",
    "    \n",
    "    if analysis:   \n",
    "        sorted_rejalt.append(score)\n",
    "        analysis_df.loc[N] = sorted_rejalt \n",
    "    \n",
    "      \n",
    "    return {'missed':missed, 'score':score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post='<td class=\"correct\"> True&lt;18%&gt;</td>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post=re.sub('&lt;&lt;','<span class=\"answered_by\">',post)\n",
    "post=re.sub('&gt;&gt;','</span>',post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QIDs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QIDs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QIDs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QIDs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(QIDs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QIDs[3]=[1, 13, 6, 4, 7, 9, 3, 5, 12, 11, 0, 10, 8, 1, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,len(QIDs)):\n",
    "    print(n)\n",
    "    assert(len(set(QIDs[n]))==len(QIDs[0])),\"same question from v0 mapped to multiple questions in another version\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda row: row.astype(str).str.contains('ANAWATE').any(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(datafilename, header=None, usecols=[0,1,2], names = [\"Srl No\", \"Name\", \"Answers\"], dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists(\"All.xlsx\"):\n",
    "    print(\"Using All\")\n",
    "elif os.path.exists(\"All_fakes.xlsx\"):\n",
    "    print(\"Using All_fakes.xlsx\")\n",
    "else:\n",
    "    print(\"Make sure either All or All_fakes is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert da, \"Hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = df[df['Answers'].map(len)!=numberOfQuestions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd =  df[df['Answers'].map(len) not [numberOfQuestions-1, numberOfQuestions].any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dd.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 not in [1,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = \"hello\"\n",
    "u[:-1]+'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = '24421124120221 '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans[-1]==\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = ans[:-1]+str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(QIDs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Answers'].str[-1] == ' ') & (df['Answers'].map(len) == numberOfQuestions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_length =  df[(df['Answers'].map(len)<numberOfQuestions-1) | (df['Answers'].map(len)>numberOfQuestions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "tstfiles=glob.glob(\"*.tst\")\n",
    "tstname = tstfiles[0][:-5]\n",
    "# test_names = [x[:-4] for x in pdf_tests]\n",
    "# tests_ending_with_digits = [x[:-1] for x in test_names if x[-1].isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstname = tstfiles[0][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
