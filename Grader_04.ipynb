{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import random\n",
    "import time\n",
    "import string\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "def text_between_subtrings(s, start, end):\n",
    "    return s.find(start), s.find(end)\n",
    "\n",
    "def wordify(question, max_words=10):\n",
    "    question_words=question.split()\n",
    "    if len(question_words)>max_words:\n",
    "        question_words=question_words[:max_words]\n",
    "    q=' '.join(question_words)\n",
    "    #q=''.join(\"0\" if c.isdigit() else c for c in q)\n",
    "    q=re.sub('\\d+', '#', q)#convert multiple digits to single digits\n",
    "    q=re.sub('#.#', '#', q)#convert multiple digits to single digits\n",
    "    q=re.sub('_+', '', q)\n",
    "    q=re.sub('\\d+\\)', '', q)#these two lines get rid of any 3) _______ crap\n",
    "    if \"version is this\" in q:\n",
    "        q = re.sub('[\\bA-E]', 'V', q)  \n",
    "        q = re.sub('#\\)', '', q)\n",
    "    else:\n",
    "        \"Make sure the version question reads: What version is this test\"\n",
    "    return q.strip()\n",
    "\n",
    "def extract_questions(s, max_words=10):\n",
    "    more='yes'\n",
    "    n=1\n",
    "    questionlist=[]\n",
    "    while more=='yes':\n",
    "        start = '\\n'+str(n)\n",
    "        end = '\\n'+str(n+1)\n",
    "        p1, p2 = text_between_subtrings(s, start, end)\n",
    "        if p1!=-1 and p2!=-1:\n",
    "            txt=s[p1+len(start):p2]\n",
    "            ###Grab the part between ) and nA, and convert into words\n",
    "            pp1, pp2 = text_between_subtrings(txt, ')', '\\nA')\n",
    "            txt=txt[1:txt.find('\\nA')]\n",
    "            txt=wordify(txt,max_words)\n",
    "            questionlist.append(txt)\n",
    "            n+=1\n",
    "        elif p1!=-1 and p2==-1:\n",
    "            txt=s[p1+len(start):]\n",
    "            pp1, pp2 = text_between_subtrings(txt, ')', '\\nA')\n",
    "            txt=txt[1:txt.find('\\nA')]\n",
    "            txt=wordify(txt,max_words)\n",
    "            #re.sub('[^A-Z]', '', s)\n",
    "            questionlist.append(txt)\n",
    "            more='no'\n",
    "        else:\n",
    "            print(\"Sum ting wong. Shouldn't go here. p1= \"+str(p1)+\" p2= \"+str(p2))\n",
    "            more='no'\n",
    "    return questionlist\n",
    "    \n",
    "\n",
    "def check_uniqueness_of_QIDs(All_IDs):\n",
    "    rr=range(len(All_IDs))\n",
    "    combs=list(itertools.combinations(rr,2))\n",
    "    for comb in combs:\n",
    "        u=[x for x in All_IDs[comb[0]] if x not in All_IDs[comb[1]]]\n",
    "        if u:\n",
    "            print(\"Oops! Some question ID's are not unique: \"+str(comb[0])+' and '+str(comb[1]))\n",
    "\n",
    "def createQuestionIDs(max_words=10):\n",
    "    All_IDs=[]\n",
    "    for n in range(0,6):\n",
    "        filename=\"key\"+str(n)+\".txt\"\n",
    "        if (os.path.isfile(filename)):\n",
    "            with open(filename, encoding=\"utf-8\") as file:  \n",
    "                data = file.read()\n",
    "            p=data.rfind('\\n\\n\\n\\n1)')\n",
    "            if p!=-1: \n",
    "                questions=data[:p]\n",
    "            else:\n",
    "                print('Make sure questions and answers in key'+str(n)+' are separated by \\n\\n\\n\\n')\n",
    "                return []\n",
    "            All_IDs.append(extract_questions(questions, max_words))\n",
    "            check_uniqueness_of_QIDs(All_IDs)\n",
    "    return All_IDs      \n",
    "\n",
    "def getAllKeys(fixed_points_per_question=1):\n",
    "    '''read all files named key0-key4, make them into strings and and return a dictionary\n",
    "    containing a list of keys and also the number of questions'''\n",
    "    keylist=[]\n",
    "    pointlist=[]\n",
    "    for n in range(0,6):\n",
    "        filename=\"key\"+str(n)+\".txt\"\n",
    "        if (os.path.isfile(filename)):\n",
    "            with open(filename, encoding=\"utf-8\") as file: \n",
    "                data = file.read()\n",
    "            u=re.search('\\n\\n\\n\\n+1\\)',data)\n",
    "            if u is not None:\n",
    "                answers=data[u.start():].strip()\n",
    "            else:\n",
    "                print('Make sure questions and answers in key'+str(n)+' are separated by \\n\\n\\n\\n')\n",
    "                return None\n",
    "\n",
    "            ukey=re.findall('[\\bA-E]',answers)\n",
    "            ukey=[str(ord(x)-65) for x in ukey]\n",
    "            key=''.join(ukey)\n",
    "            keylist.append(key)\n",
    "            \n",
    "            qnum=len(key)\n",
    "\n",
    "            #This assumes that the answerkey contains points EITHER in the user-supplied form 8) A /tab 3/n OR testgen-supplied form \"Points: 3\"\n",
    "            upoints=re.findall('\\t\\d+',answers)+re.findall(':\\s\\d+',answers)\n",
    "            if upoints:\n",
    "                _=''.join(upoints)\n",
    "                points=re.sub('[^ \\d+]',' ', _).split()\n",
    "                points=[int(x) for x in points ]\n",
    "                assert(len(points)==qnum)\n",
    "            else:\n",
    "                points=[fixed_points_per_question]*qnum\n",
    "            \n",
    "            points[-1]=0\n",
    "            pointlist.append(points)\n",
    "    \n",
    "    if not keylist:\n",
    "        print(\"Answerkeys not found. Make sure they are named key0.txt, key1.txt etc\")\n",
    "    return {\"keylist\":keylist,\"pointlist\":pointlist,\"numberOfQuestions\":qnum}\n",
    "\n",
    "def process_grades(data,outs, QIDs,analysis=False):\n",
    "    '''grades all exams using correct keys, writes questions missed and scores'''\n",
    "\n",
    "    for NN in range(0, data.shape[0]):\n",
    "        #print(\"NN: \"+str(NN))\n",
    "        ans=data.iat[NN,2]\n",
    "        if len(ans)==numberOfQuestions-1:\n",
    "            v=guess_the_version(ans)\n",
    "            ans=ans+str(v)\n",
    "            print(\"Assuming version \"+invkeydictionary[v]+ \" for: \"+data.iat[NN,1]+\" (Srl No: \"+data.iat[NN,0]+\").\")\n",
    "        check1=gradeWithKeylist(ans, outs, QIDs, analysis, NN)\n",
    "        data.iat[NN,3]=check1['missed']\n",
    "        data.iat[NN,4]=check1['score']\n",
    "        data.iat[NN,5]=100.0*float(check1['score'])/float(new_totalpoints)\n",
    "\n",
    "    if analysis:\n",
    "        #remove the column with the version numbers\n",
    "        analysis_df.drop(analysis_df.columns[analysis_df.shape[1]-2], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def gradeWithKeylist(ans,outs, QIDs, analysis=False, N=0):\n",
    "    '''multiple versions - find the correct key as indicated on the last question on the exam '''\n",
    "    keylist=outs[\"keylist\"]\n",
    "    pointlist=outs[\"pointlist\"]\n",
    "    numberOfQuestions=outs[\"numberOfQuestions\"] \n",
    "    \n",
    "    assert(keylist!=[])\n",
    "    assert (ans[-1:] in ['0','1','2','3','4'])\n",
    "    whichKey=int(ans[-1:])\n",
    "    \n",
    "    key=keylist[whichKey]\n",
    "    points=pointlist[whichKey]\n",
    "    assert len(key)==len(ans)\n",
    "    missed=\"\"\n",
    "    rejalt=[1]*numberOfQuestions\n",
    "    for n in range(0,len(key)-1):\n",
    "        if key[n]!=ans[n]:\n",
    "            #print(\"storing\")\n",
    "            missed+=str(n+1)+\", \"\n",
    "            rejalt[n]=0\n",
    "    if sum(rejalt)==numberOfQuestions:\n",
    "        missed=\"ALL CORRECT\"\n",
    "    else:\n",
    "        missed=\"v\"+invkeydictionary[whichKey]+\": \"+missed[:len(missed)-2]\n",
    "    score=sum([i*j for i,j in zip(points,rejalt)])\n",
    "    \n",
    "\n",
    "    mydict1 = dict(zip(QIDs[whichKey],rejalt))\n",
    "    #sortedIDs=sorted(mydict1.keys())\n",
    "    sorted_rejalt=[mydict1[k] for k in QIDs[0]]####its sorted according to v0\n",
    "    \n",
    "\n",
    "    \n",
    "    if analysis:   \n",
    "        sorted_rejalt.append(score)\n",
    "        analysis_df.loc[N] = sorted_rejalt \n",
    "        \n",
    "        mydict2 = dict(zip(QIDs[whichKey],ans))  \n",
    "        #sortedIDs=sorted(mydict2.keys())\n",
    "        sorted_ans=[mydict2[k] for k in QIDs[0]]\n",
    "        allAnswers_df.loc[N] = sorted_ans\n",
    "    \n",
    "\n",
    "        \n",
    "    return {'missed':missed, 'score':score}\n",
    "\n",
    "\n",
    "def guess_the_version(no_version):\n",
    "    scores=[]\n",
    "    for n in range(numberOfVersions):\n",
    "        try_version=no_version+str(n)\n",
    "        check1=gradeWithKeylist(try_version, outs, QIDs, analysis=False)\n",
    "        scores.append(check1['score'])\n",
    "    return scores.index(max(scores))\n",
    "\n",
    "def count_how_many(col, value):\n",
    "    '''takes a pandas series \"col\" and counts the number of instances of a \"value\" \n",
    "    Not used since pandas has a built-in function'''\n",
    "    \n",
    "    count=0\n",
    "    for n in range(0,col.shape[0]):\n",
    "        if col[n]==value:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "def addStarsToCorrectChoices(rdf, keylist, m, QIDS):\n",
    "    '''adds stars to correct choices in rdf'''\n",
    "    for n in range(0,rdf.shape[0]):\n",
    "        if m!=0:\n",
    "            mydict0 = dict(zip(QIDs[m],keylist[m])) \n",
    "            sortedkey=[mydict0[x] for x in QIDs[0]]\n",
    "        else:\n",
    "            sortedkey=keylist[m]\n",
    "        the_correct_answer=sortedkey[n]\n",
    "        if the_correct_answer in list(rdf):\n",
    "            rdf.iloc[n][the_correct_answer]=rdf.iloc[n][the_correct_answer]+\"*\"\n",
    "    return rdf\n",
    "\n",
    "def analyse_items(a_df, QIDs):\n",
    "    '''create separate dfs with how many marked correct for each version separately'''\n",
    "    vers=['0','1','2','3','4']\n",
    "    lvers=['A','B','C','D','E']\n",
    "    outvars=[]\n",
    "    versionsfound=[]\n",
    "    for n in range(0,len(QIDs)):\n",
    "        ch=str(n)\n",
    "        ##check the last column \"which version...\" to find the version and see if it matches ch\n",
    "        part_df = a_df.loc[a_df[QIDs[0][-1]]==ch]\n",
    "        if not part_df.empty:\n",
    "            print(\"Analysing data for version: \"+lvers[n])\n",
    "            part_df=part_df.T\n",
    "            part_df=part_df.apply(pd.Series.value_counts, axis=1).fillna(0)\n",
    "            part_df=part_df.applymap(int)\n",
    "            part_df=part_df.applymap(str)\n",
    "            part_df=addStarsToCorrectChoices(part_df,keylist,n, QIDs)\n",
    "            if ' ' in list(part_df):\n",
    "                part_df.rename(columns={' ': 'blank'}, inplace=True)   \n",
    "            for pp in vers:\n",
    "                if pp in list(part_df):\n",
    "                    part_df.rename(columns={pp: lvers[int(pp)]}, inplace=True)\n",
    "            outvars.append(part_df)\n",
    "            versionsfound.append(lvers[n])\n",
    "    \n",
    "#     Return a dict so that the html function knows which version each table belongs to    \n",
    "    return dict(zip(versionsfound,outvars))\n",
    "\n",
    "def make_item_analysis(a_df):\n",
    "    \n",
    "    item_analysis_df=pd.DataFrame(index=[\"Difficulty\",\"Discrimination\"],columns = list(analysis_df))\n",
    "    n=a_df.shape[0]\n",
    "    v=analysis_df.values#converts into np array\n",
    "    \n",
    "    \n",
    "    #Calculating Difficulty\n",
    "    u1=np.sum(v,axis=0)/n\n",
    "    item_analysis_df.loc[\"Difficulty\"]=u1[0:u1.shape[0]]\n",
    "    \n",
    "    #Calculating Discrimination\n",
    "    students_per_group=n//3\n",
    "    if students_per_group<2:\n",
    "        print(\"Need more students for discrimination analysis (at least 7).\")\n",
    "    else:\n",
    "        v=v[0:v.shape[0]-1,:]#exclude the bottom row which had the sums (total number correct for each q)\n",
    "        v=v[v[:,v.shape[1]-1].argsort()[::-1]]#sort descending by scores\n",
    "        #print(v)\n",
    "        u1=np.sum(v[0:students_per_group,:],axis=0)#top scorers\n",
    "        u2=np.sum(v[n-students_per_group : n,:],axis=0)#bottom scorers\n",
    "        disc=(u1-u2)/students_per_group\n",
    "        disc.shape\n",
    "        item_analysis_df.loc[\"Discrimination\"]=disc[0:disc.shape[0]]\n",
    "    \n",
    "    item_analysis_df.drop(\"score\", axis=1, inplace=True)\n",
    "    return item_analysis_df.T\n",
    "\n",
    "#################Writing data#############################\n",
    "def write_to_xl(adf, rfilename):\n",
    "    adf.rename(columns={'Srl No': 'Serial Number Text Grade <Text>'})#This facilitates the Vlookup later\n",
    "    writer = pd.ExcelWriter(rfilename+'_processed.xlsx')\n",
    "    adf.to_excel(writer,'Sheet1',index=False)\n",
    "    writer.save()\n",
    "    \n",
    "def write_to_csv(adf, rfilename):\n",
    "    filename = rfilename+'_processed.csv'\n",
    "    #adf=adf.rename(columns={'Srl No': 'Serial Number Text Grade <Text>'})#This facilitates the Vlookup later\n",
    "    adf.to_csv(filename, index=False)\n",
    "    \n",
    "\n",
    "def write_to_webpage(j_df, a_df,ia_df,ncbv={}, histobin=11):\n",
    "    filename = rawdatafilename+'_summary.html'\n",
    "    f = open(filename,'w',encoding='utf8')\n",
    "    \n",
    "    uu=df['Percentage'].describe().to_frame()\n",
    "    uu.rename(columns={'Percentage': \"Value\"}, index={'count':'Number of Students','mean':'Mean(%)', 'std':'Standard Deviation', 'min':'Lowest(%)','25%':'25th percentile', '50%':'50th percentile', '75%':'75th percentile', 'max':\"Highest(%)\"},inplace=True)\n",
    "    uu.loc['Maximum Available(%) '] = [100*totalpoints/new_totalpoints]\n",
    "    uu.loc['Points dropped '] = [point_drop]\n",
    "\n",
    "    pre=\"<h2>Summary Data:</h2>\"\n",
    "    summary_table=uu.to_html(float_format=lambda x: '%10.2f' % x).replace(\"dataframe\" ,\"sumdat\")\n",
    "    summary_table=pre+summary_table\n",
    "    post=\"<p>Score Distribution:</p>\"\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    df['Percentage'].plot(kind='hist', bins=10)\n",
    "    plt.xlim(xmax=100*totalpoints/new_totalpoints)\n",
    "    figure.savefig('histo.svg')\n",
    "    \n",
    "    pre=\"<h2>Score Distribution:</h2>\"\n",
    "    image_code='<img src=\"histo.svg\" alt=\"histogram\">'\n",
    "    image=pre+image_code\n",
    "\n",
    "    pre=\"<h2>Item Analysis:</h2>\"\n",
    "    item_analysis_table=ia_df.sort_values('Difficulty').to_html(float_format=lambda x: '%10.2f' % x).replace(\"dataframe\" ,\"customers\")\n",
    "    item_analysis_table=pre+item_analysis_table\n",
    "\n",
    "    missed_tables=\"\"\n",
    "    if ncbv:\n",
    "        for ver in ['A', 'B','C','D','E']:\n",
    "            if ver in ncbv.keys():\n",
    "                pre=\"<h2>Distractor Analysis for Version \"+ver+\":</h2>\"\n",
    "                post=ncbv[ver].to_html().replace(\"dataframe\" ,\"howmany\")\n",
    "                missed_tables+=pre+post\n",
    "\n",
    "\n",
    "    html_start = \"\"\"<html>\n",
    "    <head>\n",
    "     <link rel=\"stylesheet\" type=\"text/css\" href=\"mystyle.css\">\n",
    "    </head>\n",
    "    <body>\n",
    "    <h1>Data Analysis</h1>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    html_end='''</body>\n",
    "    </html>'''\n",
    "    message=html_start+summary_table+image+item_analysis_table+missed_tables+html_end\n",
    "    f.write(message)\n",
    "    f.close()\n",
    "\n",
    "    #Change path to reflect file location\n",
    "    webbrowser.open_new_tab(filename)\n",
    "\n",
    "###############################################\n",
    "## Functions that create fake data#############\n",
    "\n",
    "def create_afake(number_of_versions, blanks=False):\n",
    "    '''creates a fake answerkey'''\n",
    "    ansstring=[]\n",
    "    if not blanks:\n",
    "        choices=[0,1,2,3,4]\n",
    "    else:\n",
    "        choices=[0,1,2,3,4,' ']\n",
    "    for n in range(25):\n",
    "        ans=random.randrange(0,len(choices))\n",
    "        ansstring.append(str(choices[ans]))\n",
    "    ans=random.randrange(0,number_of_versions)\n",
    "    ansstring.append(str(ans))\n",
    "    ansstring=''.join(ansstring)\n",
    "    return ansstring\n",
    "def create_fakes(N, number_of_versions, blanks=False):\n",
    "    '''creates fakes and writes to an excel file'''\n",
    "    fakes_df=pd.DataFrame(index=range(N),columns = range(3),dtype=str)\n",
    "    fakes_df.iloc[:,0:2] =\"\"\n",
    "    for i in range(0,N):\n",
    "        fakes_df.iat[i,2]=create_afake(number_of_versions, blanks)\n",
    "    writer = pd.ExcelWriter('fakes.xlsx')\n",
    "    fakes_df.to_excel(writer,'Sheet1')\n",
    "    writer.save()\n",
    "\n",
    "########################################################\n",
    "############### Checking for incorrect Srl Nos################\n",
    "\n",
    "def find_oks(row):\n",
    "    return row['Name'].find(row['First Name'].upper())!=-1 and not row['Name'].isnull()\n",
    "def remove_ok_rows(df):\n",
    "    notnull=df.dropna()\n",
    "    okrows=notnull.loc[notnull.apply(find_oks, axis=1)]\n",
    "    oksremoved=pd.concat([df, okrows]).drop_duplicates(keep=False)\n",
    "    return oksremoved\n",
    "\n",
    "def check_serial_numbers():\n",
    "    df=pd.read_csv('BSGrades.csv', usecols=[\"Last Name\", \"First Name\", \"Serial Number Text Grade <Text>\"])\n",
    "    df_all=pd.read_excel('All.xlsx', header=None, parse_cols=1,names = [\"Serial Number Text Grade <Text>\", \"Name\"])\n",
    "\n",
    "    checker_left = pd.merge(df,df_all[['Serial Number Text Grade <Text>','Name']],on='Serial Number Text Grade <Text>', how='left')\n",
    "    checker_right = pd.merge(df,df_all[['Serial Number Text Grade <Text>','Name']],on='Serial Number Text Grade <Text>', how='right')\n",
    "    u1=checker_left[checker_left.isnull().any(axis=1)]\n",
    "    u2=checker_left[checker_left['Serial Number Text Grade <Text>'].duplicated(keep=False)]\n",
    "    u3=checker_right[checker_right.isnull().any(axis=1)]\n",
    "    error_rpt=pd.concat([u1, u2, u3], axis=0)\n",
    "#     display(error_rpt)\n",
    "#     if not error_rpt.empty:\n",
    "#         error_rpt=remove_ok_rows(error_rpt)\n",
    "    error_rpt[\"Last Name\"] = error_rpt[\"Last Name\"]+' '+error_rpt['First Name']\n",
    "    error_rpt.drop('First Name', axis=1,inplace=True)\n",
    "    error_rpt.rename(columns={'Serial Number Text Grade <Text>': 'Srl No', 'Last Name':'Registered Name', 'Name':'Entered Name'}, inplace=True) \n",
    "    return error_rpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually convert the dat file into an excel file using excel. Only extract the serial number,\n",
    "name and Answers, and make sure Answers is text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srl No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1009</td>\n",
       "      <td>HAN KARIN</td>\n",
       "      <td>0110241 21 4040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Srl No       Name          Answers\n",
       "2   1009  HAN KARIN  0110241 21 4040"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Registered Name</th>\n",
       "      <th>Srl No</th>\n",
       "      <th>Entered Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolling Atiyaa</td>\n",
       "      <td>1003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Muezzinoglu Mine</td>\n",
       "      <td>1018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carlson Brynn</td>\n",
       "      <td>1002</td>\n",
       "      <td>CARLSON BRYNN L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carlson Brynn</td>\n",
       "      <td>1002</td>\n",
       "      <td>MUEZZINOGLU MINE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Registered Name  Srl No      Entered Name\n",
       "1     Bolling Atiyaa    1003               NaN\n",
       "12  Muezzinoglu Mine    1018               NaN\n",
       "2      Carlson Brynn    1002   CARLSON BRYNN L\n",
       "3      Carlson Brynn    1002  MUEZZINOGLU MINE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#COLLECTING DATA\n",
    "rawdatafilename='All'\n",
    "xls_file = pd.ExcelFile(rawdatafilename+'.xlsx')\n",
    "df = xls_file.parse('Sheet1', header=None, parse_cols=2,names = [\"Srl No\", \"Name\", \"Answers\"], dtype='str')\n",
    "#parse_cols makes sure that only cols 0,1 and 2 are extracted\n",
    "#checking for blanks, print only if blanks found\n",
    "if not df[df['Answers'].str.contains(\" \")].empty:\n",
    "    blankers=df[df['Answers'].str.contains(\" \")]\n",
    "    display(blankers)\n",
    "ER=check_serial_numbers()\n",
    "if not ER.empty:\n",
    "    display(ER)\n",
    "df[\"Missed\"] = \"\"\n",
    "df[\"Score\"]=0\n",
    "df[\"Percentage\"]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initializing everything\n",
    "keydictionary={\"A\":\"0\",\"B\":\"1\",\"C\":\"2\",\"D\":\"3\",\"E\":\"4\"}\n",
    "invkeydictionary={0:\"A\",1:\"B\",2:\"C\",3:\"D\",4:\"E\"}\n",
    "points_per_question=3\n",
    "point_drop=2\n",
    "outs = getAllKeys(points_per_question)\n",
    "keylist=outs[\"keylist\"]\n",
    "pointlist=outs[\"pointlist\"]\n",
    "numberOfQuestions=outs[\"numberOfQuestions\"]\n",
    "if not keylist or not pointlist or numberOfQuestions==0:\n",
    "    sys.exit(\"Keys not properly imported\")\n",
    "totalpoints=sum(pointlist[2])\n",
    "new_totalpoints=totalpoints-point_drop\n",
    "numberOfVersions=len(keylist)\n",
    "numberOfStudents=df.shape[0]\n",
    "QIDs=createQuestionIDs(numberOfQuestions)\n",
    "headings=list(QIDs[0])#####headings=QIDs[0] assigns by reference, so changing headings will change QIDs[0]\n",
    "allAnswers_df = pd.DataFrame(index=range(numberOfStudents), columns = headings)# stores all student answers for each question, questions are the columns\n",
    "#results_df = pd.DataFrame(index=headings, columns = [\"A\",\"B\",\"C\",\"D\",\"E\",\"Skipped\",\"Diff\",\"Disc\"])\n",
    "headings.append(\"score\")\n",
    "analysis_df  = pd.DataFrame(index=range(numberOfStudents),columns = headings)# stores whether answer was correct, questions are the columns, last column is the score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting calculations...\n",
      "Analysing data for version: A\n",
      "Analysing data for version: B\n",
      "Analysing data for version: C\n",
      "Analysing data for version: D\n",
      "Done. That took: 0.13663434982299805 sec for 20 students\n"
     ]
    }
   ],
   "source": [
    "##Everything initialized. Running the code now\n",
    "didnt_enter_versions=df[df['Answers'].map(len)!=numberOfQuestions]\n",
    "if not didnt_enter_versions.empty:\n",
    "    didnt_enter_versions=didnt_enter_versions[['Srl No', 'Name','Answers']]\n",
    "    display(didnt_enter_versions)\n",
    "print(\"Starting calculations...\")\n",
    "starttime = time.time()\n",
    "df=process_grades(df,outs, QIDs, analysis=True)\n",
    "number_correct_by_version=analyse_items(allAnswers_df, QIDs)\n",
    "item_analysis_df = make_item_analysis(analysis_df) \n",
    "endtime = time.time()\n",
    "print(\"Done. That took: \"+str(endtime-starttime)+ \" sec for \"+str(numberOfStudents)+\" students\")\n",
    "#check for duplicated serial numbers\n",
    "if not df[df['Srl No'].duplicated(keep=False)].empty:\n",
    "    print('Warning: Duplicates in serial numbers found!')\n",
    "    dupes=df[df['Srl No'].duplicated(keep=False)]\n",
    "max_score=analysis_df.at[analysis_df['score'].idxmax(),'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write_to_csv(df,rawdatafilename)\n",
    "write_to_webpage(df, analysis_df, item_analysis_df,number_correct_by_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13: CARLSON BRYNN L, 2009. Missed ALL CORRECT. Scored 42/42\n",
      "That is: 105.0% with 2 points dropped\n"
     ]
    }
   ],
   "source": [
    "#Grades and displays the N'th entry in the list using a keylist\n",
    "#N=random.randint(1,df.shape[0]-1)\n",
    "#for N in range(df.shape[0]-1):\n",
    "N=13\n",
    "check1=gradeWithKeylist(df.iat[N,2], outs, QIDs, analysis=False)\n",
    "print(\"Row \"+ str(N)+\": \"+df.iat[N,1]+\", \"+str(df.iat[N,0])+\". Missed \"+str(check1['missed'])+ \". Scored \"+str(check1['score'])+\"/\"+str(totalpoints))\n",
    "print('That is: '+str(100*check1['score']/new_totalpoints)+'% with '+str(point_drop)+' points dropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####ANSWER EXTRACTION############################\n",
    "\n",
    "###This part just reads the questions as usual\n",
    "filename=\"key\"+str(0)+\".txt\"\n",
    "if (os.path.isfile(filename)):\n",
    "    with open(filename, encoding=\"utf-8\") as file:  \n",
    "        data = file.read()\n",
    "    p=data.rfind('\\n\\n\\n\\n1)')\n",
    "    if p!=-1: \n",
    "        questions=data[:p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A) 4.60 m/s2', 'B) 9.80 m/s2', 'C) 2.30 m/s2', 'D) 3.29 m/s2', 'E) 3.07 m/s2']\n",
      "['A) 900 m/s.', 'B) 1300 m/s.', 'C) 1200 m/s.', 'D) 1100 m/s.', 'E) 1000 m/s.']\n",
      "['A) -2.2 N • m.', 'B) 2.2 N • m.', 'C) 4.0 N • m.', 'D) -4.0 N • m.', 'E) zero']\n",
      "['A) 35 s.', 'B) 50 s.', 'C) 268 s.', 'D) 25 s.', 'E) 13 s.']\n",
      "['A) 2.4 m/s', 'B) 5.4 m/s', 'C) 4.6 m/s', 'D) None of these', 'E) 3.0 m/s']\n",
      "['A) 10.0  m/s2', 'B) 13.3 m/s2', 'C) 30.0  m/s2', 'D) 16.0 m/s2', 'E) None of these']\n",
      "['A) 40.0 N', 'B) 107 N', 'C) 13.3 N', 'D) 26.7 N', 'E) 16.7 N']\n",
      "['A) 7/5 I', 'B) 2/7 I', 'C) 1/7 I', 'D) 2/5 I', 'E) 3/5 I']\n",
      "['A) to your right', 'B) to your left', 'C) down', 'D) forwards', 'E) up']\n",
      "['A) Deflect the ball.', 'B) Catch the ball.', 'C) Your final speed on the skateboard will be the same regardless whether you catch the ball or deflect the ball.', '', '']\n",
      "['A) sphere, hoop, disk', 'B) hoop, disk, sphere', 'C) sphere, disk, hoop', 'D) hoop, sphere, disk', 'E) disk, hoop, sphere']\n",
      "['A) (3/2)mb2', 'B) (1/3)mb2', 'C) (1/2)mb2', 'D) (1/18)mb2', 'E) (7/12)mb2']\n",
      "['A) partially inelastic.', 'B) perfectly elastic.', 'C) completely inelastic.', 'D) characterized by an increase in kinetic energy.', 'E) not possible because momentum is not conserved.']\n",
      "['A) the momentum of each object is conserved.', 'B) the kinetic energy of each object is conserved.', 'C) the kinetic energy of the system is conserved, but the momentum of the system is not conserved.', 'D) both the momentum and the kinetic energy of the system are conserved.', 'E) the momentum of the system is conserved but the kinetic energy of the system is not conserved.']\n",
      "['A)', 'B)', 'C)', 'D', '']\n"
     ]
    }
   ],
   "source": [
    "##This parts gets the answer choices for each question and stores them in an array\n",
    "for n in range(1,16):\n",
    "#n=15\n",
    "    s=questions\n",
    "    txt=''\n",
    "    start = '\\n'+str(n)\n",
    "    end = '\\n'+str(n+1)\n",
    "    p1, p2 = text_between_subtrings(s, start, end)\n",
    "    if p1!=-1 and p2!=-1:\n",
    "        txt=s[p1+len(start):p2]\n",
    "    if p1!=-1 and p2==-1:\n",
    "        txt=s[p1+len(start):]\n",
    "    anslist=[]\n",
    "    for m in range(0,4):\n",
    "        start=invkeydictionary[m]+')'\n",
    "        end=invkeydictionary[m+1]+')'\n",
    "        #p1, p2 = text_between_subtrings(txt, start, end)\n",
    "        p1=txt.rfind(start)\n",
    "        p2=txt.rfind(end)\n",
    "    #     print('p1= '+str(p1)+', p2= '+str(p2))\n",
    "        ans=txt[p1:p2].strip()\n",
    "        if ans:\n",
    "            anslist.append(ans)\n",
    "        else:\n",
    "            anslist.append('')\n",
    "    if p2!=-1:\n",
    "        ans=txt[p2:].strip()\n",
    "        anslist.append(ans)\n",
    "    else:\n",
    "        anslist.append('')\n",
    "    print(anslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "') What version is this test? (Please answer C)      15) ______\\nA)      B)      C)      D)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-8cf6306c5b02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "aa.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
