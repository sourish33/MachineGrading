{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grader - does all grading and calculating\n",
    "- Manually convert the dat file into an excel file using excel. Only extract the serial number, name and Answers, and make sure Answers is text. **Serial number should not be text**\n",
    "- Make sure all initializations in myconfig.py are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\souri\\Dropbox\\Machinegrading\\Master\\grader_funs.py:9: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "from myconfig import *\n",
    "from grader_funs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from All.xlsx\n",
      "The following scantrons had blanks in them. Please resolve before proceeding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srl No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1009</td>\n",
       "      <td>HAN KARIN</td>\n",
       "      <td>0110241221 4040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Srl No       Name          Answers\n",
       "2  1009   HAN KARIN  0110241221 4040"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Registered Name</th>\n",
       "      <th>Srl No</th>\n",
       "      <th>Entered Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolling Atiyaa</td>\n",
       "      <td>1003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Muezzinoglu Mine</td>\n",
       "      <td>1018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carlson Brynn</td>\n",
       "      <td>1002</td>\n",
       "      <td>CARLSON BRYNN L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carlson Brynn</td>\n",
       "      <td>1002</td>\n",
       "      <td>MUEZZINOGLU MINE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Registered Name  Srl No      Entered Name\n",
       "1   Bolling Atiyaa    1003    NaN             \n",
       "12  Muezzinoglu Mine  1018    NaN             \n",
       "2   Carlson Brynn     1002    CARLSON BRYNN L \n",
       "3   Carlson Brynn     1002    MUEZZINOGLU MINE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rawdatafilename = ''\n",
    "if os.path.exists(good_name+\".xlsx\"):\n",
    "    rawdatafilename=good_name\n",
    "    datafilename=rawdatafilename+'.xlsx'\n",
    "    trash_files('*fake*')\n",
    "\n",
    "if os.path.exists(fake_name+\".xlsx\"):\n",
    "    rawdatafilename= fake_name\n",
    "    datafilename=rawdatafilename+'.xlsx'\n",
    "\n",
    "assert rawdatafilename, \"Make sure either {} or {} is ready\".format(good_name,fake_name)\n",
    "print(\"Using data from {}.xlsx\".format(rawdatafilename))\n",
    "\n",
    "\n",
    "# gradebook='BSGrades.csv'\n",
    "assert(os.path.isfile(datafilename)),'Make sure '+datafilename+\" is ready\"\n",
    "assert(os.path.isfile(gradebook)),'Make sure '+gradebook+' is ready'\n",
    "\n",
    "df = pd.read_excel(datafilename, header=None, usecols=[0,1,2], names = [\"Srl No\", \"Name\", \"Answers\"], dtype='str')\n",
    "#parse_cols makes sure that only cols 0,1 and 2 are extracted\n",
    "just_answers_df=df.loc[:,\"Answers\"]\n",
    "#checking for blanks, print only if blanks found\n",
    "asterisks = False\n",
    "blankers=df[df['Answers'].str.contains(\" \")]\n",
    "stars = df[df['Answers'].str.contains('\\*')]\n",
    "if not blankers.empty:\n",
    "    print(\"The following scantrons had blanks in them. Please resolve before proceeding.\")\n",
    "    display(blankers)\n",
    "if not stars.empty:\n",
    "    print(\"The following scantrons were flagged as unclear. Please resolve before proceeding.\")\n",
    "    display(stars)\n",
    "    asterisks = True\n",
    "ER=check_serial_numbers(gradebook,datafilename)\n",
    "if not ER.empty:\n",
    "    display(ER)\n",
    "\n",
    "df[\"Missed\"] = \"\"\n",
    "df[\"Score\"]=0\n",
    "df[\"Percentage\"]=np.nan\n",
    "number_of_questions_from_scantrons=len(df.loc[0,\"Answers\"])\n",
    "available_points = (number_of_questions_from_scantrons-1)*points_per_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming answerkey files are in the .txt files named test1_v\n",
      "1 QUESTIONS ARE BEING AWARDED FREE POINTS! (CHECK MYCONFIG.PY)\n",
      "Generating QIDs. This might take a while..\n",
      "Done. That took: 0.8904180526733398 sec.\n",
      "18x3=54 points available, but grading out of 51, dropping 3 points for a midterm.\n"
     ]
    }
   ],
   "source": [
    "assert not asterisks, \"Please resolve the answerkeys with *'s in them before proceeding'\"\n",
    "\n",
    "\n",
    "#determining whether the test in question is a final or a midterm. 3 points dropped for a final and 2 points dropped for a midterm\n",
    "tstfiles=glob.glob(\"*.tst\")#get all tst files\n",
    "tstnames=[x[:-5] for x in tstfiles]# make list of the file names\n",
    "tstname = most_frequent(tstnames)# pick the most common file name, assuming that is the actual test\n",
    " \n",
    "\n",
    "assert os.path.exists(tstname+\"0.txt\") |  os.path.exists(\"key0.txt\"), \"answerkey0 not found. Make sure it is named key0.txt or something like 2019_test1v0.txt\"\n",
    "  \n",
    "if not os.path.exists(tstname+\"0.txt\"):\n",
    "        tstname = \"key\"\n",
    "print(\"Assuming answerkey files are in the .txt files named {}\".format(tstname))   \n",
    "\n",
    "if bool([x for x in tstfiles if \"final\" in x.lower()]):\n",
    "    point_drop = point_drop_final\n",
    "    fin = True\n",
    "else:\n",
    "    point_drop = point_drop_midterm\n",
    "    fin = False\n",
    "    \n",
    "if freebies:\n",
    "    print(\"{} questions are being awarded free points! (check myconfig.py)\".format(len(freebies)).upper())\n",
    "\n",
    "\n",
    "if skipped_questions:\n",
    "    print(\"{} questions are being skipped!(check myconfig.py)\".format(len(skipped_questions)).upper())\n",
    "\n",
    "quids_dfs=createQuestionIDs_and_dfs(tstname, max_words=50)\n",
    "QIDs=quids_dfs[\"IDs\"]\n",
    "exempts=make_special_question_list(freebies, QIDs)\n",
    "skipped = make_special_question_list(skipped_questions, QIDs)\n",
    "\n",
    "outs = getAllKeys(tstname, points_per_question, skipped)\n",
    "keylist=outs[\"keylist\"]\n",
    "pointlist=outs[\"pointlist\"]\n",
    "numberOfQuestions=outs[\"numberOfQuestions\"]\n",
    "assert number_of_questions_from_scantrons == numberOfQuestions, \"The number of questions on the test ({}) does not match the number of questions on the scantron ({})\".format(numberOfQuestions,number_of_questions_from_scantrons)\n",
    "sum_pointlists =[sum(x) for x in pointlist]\n",
    "the_common_sum = set(sum_pointlists)\n",
    "assert (len(the_common_sum)==1), \"Each version should have the same total number of points\"\n",
    "totalpoints = list(the_common_sum)[0]\n",
    "new_totalpoints=totalpoints-point_drop\n",
    "\n",
    "\n",
    "if fin:\n",
    "    print(\"{}x{}={} points available, but grading out of {}, dropping {} points for a final.\".format(number_of_questions_from_scantrons-1,points_per_question, totalpoints, new_totalpoints, point_drop))\n",
    "else:\n",
    "    print(\"{}x{}={} points available, but grading out of {}, dropping {} points for a midterm.\".format(number_of_questions_from_scantrons-1,points_per_question, totalpoints, new_totalpoints, point_drop))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "numberOfVersions=len(keylist)\n",
    "numberOfStudents=df.shape[0]\n",
    "\n",
    "koschen_paper=quids_dfs['dfs']\n",
    "v0_question_list = list(koschen_paper[0].loc[:,\"Question\"]) #List of questions in version 0\n",
    "assert(keylist and pointlist and QIDs and koschen_paper and numberOfQuestions!=0),\"Either keylist or pointlist or QIDs or koschen_paper or  numberOfQuestions is null\"\n",
    "\n",
    "\n",
    "analysis_df  = pd.DataFrame(index=range(numberOfStudents),columns = list(QIDs[0])+[\"score\"])# stores whether answer was correct, questions are the columns, last column is the score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting calculations...\n",
      "Analysing data for version: A\n",
      "Analysing data for version: B\n",
      "Analysing data for version: C\n",
      "Analysing data for version: D\n",
      "Analysing data for version: E\n",
      "Done. That took: 0.15623736381530762 sec for 139 students\n"
     ]
    }
   ],
   "source": [
    "##Everything initialized. Running the code now\n",
    "   \n",
    "\n",
    "incorrect_length =  df[(df['Answers'].map(len)<numberOfQuestions-1) | (df['Answers'].map(len)>numberOfQuestions)]\n",
    "if not incorrect_length.empty:\n",
    "    incorrect_length=incorrect_length[['Srl No', 'Name','Answers']]\n",
    "    print(\"The following students had too many or too few answers\")\n",
    "    display(incorrect_length)\n",
    "assert incorrect_length.empty, \"Check that all answer strings have correct length\" \n",
    "\n",
    "last_entry_missing=df[df['Answers'].map(len)==numberOfQuestions-1]\n",
    "if not last_entry_missing.empty:\n",
    "    last_entry_missing=last_entry_missing[['Srl No', 'Name','Answers']]\n",
    "    print(\"The following students had no entry for the version question\")\n",
    "    display(last_entry_missing)\n",
    "last_entry_space = df[(df['Answers'].str[-1] == ' ') & (df['Answers'].map(len) == numberOfQuestions)]\n",
    "if not last_entry_space.empty:\n",
    "    last_entry_space=last_entry_space[['Srl No', 'Name','Answers']]\n",
    "    print(\"The following students had a blank entered for version question\")\n",
    "    display(last_entry_space)\n",
    "\n",
    "print(\"Starting calculations...\")\n",
    "starttime = time()\n",
    "\n",
    "df=process_grades(df,outs, QIDs ,analysis_df, new_totalpoints, numberOfVersions, analysis=True,exempt_questions=exempts,skipped_questions = skipped)\n",
    "number_correct_by_version, students_by_version = analyse_items(df, koschen_paper,keylist)\n",
    "item_analysis_df = make_item_analysis(analysis_df, v0_question_list) \n",
    "endtime = time()\n",
    "print(\"Done. That took: \"+str(endtime-starttime)+ \" sec for \"+str(numberOfStudents)+\" students\")\n",
    "#check for duplicated serial numbers\n",
    "dupes=df[df['Srl No'].duplicated(keep=False)]\n",
    "if not dupes.empty:\n",
    "    print('Warning: Duplicates in serial numbers found!')\n",
    "    display(dupes)    \n",
    "max_score=analysis_df.at[analysis_df['score'].idxmax(),'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEQtJREFUeJzt3X2sZHV9x/H3R6DyIArIhW6B9YIhCCGy4EqxWKogFlFBTG0ljZKWsiZihJakrtT6ENOEJipqaqgoKFJLqwJKgarrlmptGnBBkMWFYHWLCGXXR/ChIvjtH3Ou3iz7MHfZM2eW3/uVTGbO756558PMXD57HidVhSSpXU8aOoAkaVgWgSQ1ziKQpMZZBJLUOItAkhpnEUhS4ywCSWqcRSBJjbMIJKlxOw4dYBx77713zc7ODh1DkrYrN99883eramZL820XRTA7O8uqVauGjiFJ25Uk/zPOfG4akqTGWQSS1DiLQJIaZxFIUuMsAklqnEUgSY2zCCSpcRaBJDXOIpCkxm0XZxZL2j7NLr9u0OWvveClgy5/e+EagSQ1ziKQpMZZBJLUOItAkhpnEUhS4ywCSWqcRSBJjbMIJKlxFoEkNc4ikKTG9VYESQ5IckOSNUnuSHJON/72JN9Jcmt3O7mvDJKkLevzWkOPAOdV1S1JdgduTrKi+9mFVfWuHpctSRpTb0VQVfcD93ePH0qyBtivr+VJkrbORPYRJJkFjgRu7IbekORrSS5NsuckMkiSNq73IkjyFOBK4NyqehC4CHgmsITRGsO7N/G8ZUlWJVm1fv36vmNKUrN6LYIkOzEqgY9X1VUAVfVAVT1aVb8EPgQcvbHnVtXFVbW0qpbOzMz0GVOSmtbnUUMBLgHWVNV75o0vmjfbacDqvjJIkrasz6OGjgVeA9ye5NZu7Hzg9CRLgALWAq/rMYMkaQv6PGroy0A28qPr+1qmJGnhPLNYkhpnEUhS4ywCSWqcRSBJjbMIJKlxFoEkNc4ikKTGWQSS1DiLQJIaZxFIUuP6vNaQ1LzZ5dcNuvy1F7x00OVr++AagSQ1ziKQpMZZBJLUOItAkhpnEUhS4ywCSWqcRSBJjbMIJKlxFoEkNc4ikKTGWQSS1DiLQJIaZxFIUuMsAklqnEUgSY2zCCSpcRaBJDXOIpCkxlkEktS43oogyQFJbkiyJskdSc7pxvdKsiLJ3d39nn1lkCRtWZ9rBI8A51XVocAxwNlJDgOWAyur6mBgZTctSRpIb0VQVfdX1S3d44eANcB+wKnAZd1slwGv6CuDJGnLJrKPIMkscCRwI7BvVd0Po7IA9tnEc5YlWZVk1fr16ycRU5Ka1HsRJHkKcCVwblU9OO7zquriqlpaVUtnZmb6CyhJjeu1CJLsxKgEPl5VV3XDDyRZ1P18EbCuzwySpM3r86ihAJcAa6rqPfN+dA1wRvf4DOAzfWWQJG3Zjj3+7mOB1wC3J7m1GzsfuAD4RJIzgXuAV/WYQZK0Bb0VQVV9GcgmfnxCX8uVJC2MZxZLUuMsAklqXJ/7CCQNbHb5dUNH0HbANQJJapxFIEmNswgkqXEWgSQ1ziKQpMZZBJLUOItAkhpnEUhS4ywCSWqcRSBJjbMIJKlxFoEkNW6sIkhyeN9BJEnDGHeN4O+T3JTk9Un26DWRJGmixroMdVU9P8nBwJ8Cq5LcBHykqlb0mk6SHoehL8O99oKXDrr8cY29j6Cq7gbeArwJ+D3g/UnuTPLKvsJJkvo37j6CZye5EFgDHA+8vKoO7R5f2GM+SVLPxv2Gsr8DPgScX1U/mxusqvuSvKWXZJKkiRi3CE4GflZVjwIkeRKwc1X9tKou7y2dJKl34+4j+AKwy7zpXbsxSdJ2btwi2Lmqfjw30T3etZ9IkqRJGrcIfpLkqLmJJM8BfraZ+SVJ24lx9xGcC3wyyX3d9CLgj/qJJEmapHFPKPtKkmcBhwAB7qyqX/SaTJI0EeOuEQA8F5jtnnNkEqrqY72kkiRNzFhFkORy4JnArcCj3XABFoEkbefGXSNYChxWVTXuL05yKfAyYF1VHd6NvR04C1jfzXZ+VV0/flxJ0rY27lFDq4HfXODv/ihw0kbGL6yqJd3NEpCkgY27RrA38PXuqqM/nxusqlM29YSq+lKS2ceVTpLUu3GL4O3bcJlvSPJaYBVwXlX9YBv+bknSAo17+OgXkzwDOLiqvpBkV2CHrVjeRcA7Ge1ofifwbkbfcfAYSZYBywAWL168FYuShr8evdq2vXz+xr0M9VnAp4APdkP7AZ9e6MKq6oGqerSqfsnoaqZHb2bei6tqaVUtnZmZWeiiJEljGndn8dnAscCD8KsvqdlnoQtLsmje5GmMdkJLkgY07j6Cn1fVw0kASLIjo807m5TkCuAFwN5J7gXeBrwgyZLuuWuB121dbEnStjJuEXwxyfnALklOBF4P/MvmnlBVp29k+JIF5pMk9WzcTUPLGZ0Edjujf8Vfz+j7iyVJ27lxjxqa27n7oX7jSJImbdxrDX2LjewTqKqDtnkiSdJELeRaQ3N2Bl4F7LXt40iSJm2sfQRV9b15t+9U1XuB43vOJkmagHE3DR01b/JJjNYQdu8lkSRposbdNPTueY8fYXQOwB9u8zSSpIkb96ihF/YdRJI0jHE3Df3F5n5eVe/ZNnEkSZO2kKOGngtc002/HPgS8O0+QkmSJmchX0xzVFU9BL/6yslPVtWf9RVMkjQZ415iYjHw8Lzph4HZbZ5GkjRx464RXA7clORqRmcYnwZ8rLdUkqSJGfeoob9J8q/A73ZDf1JVX+0vliRpUsbdNASwK/BgVb0PuDfJgT1lkiRN0LhfVfk24E3Am7uhnYB/6CuUJGlyxl0jOA04BfgJQFXdh5eYkKQnhHGL4OGqKrpLUSfZrb9IkqRJGrcIPpHkg8AeSc4CvoBfUiNJTwjjHjX0ru67ih8EDgHeWlUrek0mSZqILRZBkh2Az1XViwD/5y9JTzBb3DRUVY8CP03ytAnkkSRN2LhnFv8fcHuSFXRHDgFU1Rt7SSVJmphxi+C67iZJeoLZbBEkWVxV91TVZZMKJEmarC3tI/j03IMkV/acRZI0gC0VQeY9PqjPIJKkYWypCGoTjyVJTxBb2ll8RJIHGa0Z7NI9ppuuqnpqr+kkSb3b7BpBVe1QVU+tqt2rasfu8dz0ZksgyaVJ1iVZPW9sryQrktzd3e+5rf5DJElbZyHfR7BQHwVO2mBsObCyqg4GVnbTkqQB9VYEVfUl4PsbDJ8KzB2Kehnwir6WL0kaT59rBBuzb1XdD9Dd7zPh5UuSNjDumcUTl2QZsAxg8eLFA6fR4zG73JPSpWk26TWCB5IsAuju121qxqq6uKqWVtXSmZmZiQWUpNZMugiuAc7oHp8BfGbCy5ckbaC3IkhyBfBfwCFJ7k1yJnABcGKSu4ETu2lJ0oB620dQVadv4kcn9LVMSdLCTXrTkCRpylgEktQ4i0CSGje15xFo2/E4fkmb4xqBJDXOIpCkxlkEktQ4i0CSGmcRSFLjLAJJapxFIEmNswgkqXEWgSQ1ziKQpMZZBJLUOItAkhpnEUhS4ywCSWqcRSBJjbMIJKlxFoEkNc4ikKTGWQSS1DiLQJIaZxFIUuMsAklqnEUgSY2zCCSpcRaBJDXOIpCkxu04xEKTrAUeAh4FHqmqpUPkkCQNVASdF1bVdwdcviQJNw1JUvOGKoICPp/k5iTLNjZDkmVJViVZtX79+gnHk6R2DFUEx1bVUcBLgLOTHLfhDFV1cVUtraqlMzMzk08oSY0YpAiq6r7ufh1wNXD0EDkkSQMUQZLdkuw+9xh4MbB60jkkSSNDHDW0L3B1krnl/2NVfXaAHJIkBiiCqvomcMSklytJ2jgPH5WkxlkEktQ4i0CSGmcRSFLjLAJJapxFIEmNswgkqXEWgSQ1ziKQpMZZBJLUuCG/oawZs8uvGzqCJG2SawSS1DiLQJIaZxFIUuMsAklqnEUgSY2zCCSpcRaBJDXOIpCkxlkEktQ4i0CSGmcRSFLjLAJJapxFIEmNswgkqXFNXIbay0BL0qa5RiBJjbMIJKlxFoEkNW6QIkhyUpK7knwjyfIhMkiSRiZeBEl2AD4AvAQ4DDg9yWGTziFJGhlijeBo4BtV9c2qehj4J+DUAXJIkhimCPYDvj1v+t5uTJI0gCHOI8hGxuoxMyXLgGXd5I+T3AXsDXy3x2yPh9kWblpzgdm21rRmm9Zc0G+2Z4wz0xBFcC9wwLzp/YH7Npypqi4GLp4/lmRVVS3tN97WMdvCTWsuMNvWmtZs05oLpiPbEJuGvgIcnOTAJL8BvBq4ZoAckiQGWCOoqkeSvAH4HLADcGlV3THpHJKkkUGuNVRV1wPXb8VTL97yLIMx28JNay4w29aa1mzTmgumIFuqHrOfVpLUEC8xIUmNm9oiSHJAkhuSrElyR5JzuvG9kqxIcnd3v+eEc+2c5KYkt3W53tGNH5jkxi7XP3c7wgeRZIckX01y7TRlS7I2ye1Jbk2yqhsb9P2cl22PJJ9Kcmf3mXve0NmSHNK9VnO3B5OcO3Suefn+vPsbWJ3kiu5vY1o+a+d0ue5Icm43NsjrluTSJOuSrJ43ttEsGXl/d/mdryU5ahIZp7YIgEeA86rqUOAY4OzuUhTLgZVVdTCwspuepJ8Dx1fVEcAS4KQkxwB/C1zY5foBcOaEc813DrBm3vQ0ZXthVS2Zd7jc0O/nnPcBn62qZwFHMHr9Bs1WVXd1r9US4DnAT4Grh84FkGQ/4I3A0qo6nNGBH69mCj5rSQ4HzmJ0FYMjgJclOZjhXrePAidtMLapLC8BDu5uy4CLJpKwqraLG/AZ4ETgLmBRN7YIuGvATLsCtwC/zeiEkB278ecBnxso0/6MPljHA9cyOoFvWrKtBfbeYGzw9xN4KvAtun1m05RtXpYXA/85Lbn49RUC9mJ00Mm1wO9Pw2cNeBXw4XnTfw385ZCvGzALrN7SZwv4IHD6xubr8zbNawS/kmQWOBK4Edi3qu4H6O73GSDPDkluBdYBK4D/Bn5YVY90swx52Yz3MvrQ/7KbfjrTk62Azye5uTtzHKbg/QQOAtYDH+k2qX04yW5Tkm3Oq4EruseD56qq7wDvAu4B7gd+BNzMdHzWVgPHJXl6kl2BkxmdxDr46zbPprIMcgmeqS+CJE8BrgTOraoHh84DUFWP1mh1fX9Gq5+Hbmy2yaaCJC8D1lXVzfOHNzLrUIeKHVtVRzFa/T07yXED5djQjsBRwEVVdSTwE4bbRPUY3Xb2U4BPDp1lTrdN+1TgQOC3gN0Yva8bmvhnrarWMNpEtQL4LHAbo03N24NB/l6nugiS7MSoBD5eVVd1ww8kWdT9fBGjf5UPoqp+CPw7o30YeySZOy9jo5fNmIBjgVOSrGV0VdfjGa0hTEM2quq+7n4do23dRzMd7+e9wL1VdWM3/SlGxTAN2WD0P9hbquqBbnoacr0I+FZVra+qXwBXAb/D9HzWLqmqo6rqOOD7wN1Mx+s2Z1NZxroEz7Y2tUWQJMAlwJqqes+8H10DnNE9PoPRvoNJ5ppJskf3eBdGfxBrgBuAPxgqF0BVvbmq9q+qWUabEv6tqv54GrIl2S3J7nOPGW3zXs3A7ydAVf0v8O0kh3RDJwBfn4ZsndP59WYhmI5c9wDHJNm1+1ude80G/6wBJNmnu18MvJLR6zcNr9ucTWW5Bnhtd/TQMcCP5jYh9WqSO3EWuHPl+YxWib4G3NrdTma0zXslo4ZfCew14VzPBr7a5VoNvLUbPwi4CfgGo1X4Jw/8+r0AuHZasnUZbutudwB/1Y0P+n7Oy7cEWNW9r58G9pyGbIwOSPge8LR5Y4Pn6nK8A7iz+zu4HHjyNHzWumz/waiYbgNOGPJ1Y1RC9wO/YPQv/jM3lYXRpqEPMNrveDujo7J6z+iZxZLUuKndNCRJmgyLQJIaZxFIUuMsAklqnEUgSY2zCCSpcRaBJDXOIpCkxv0/NLsAwkZ6lQUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_to_csv(df.sort_values('Score', ascending=False),rawdatafilename)\n",
    "if (os.path.isfile('mystyle.css')):\n",
    "    write_to_webpage(rawdatafilename, totalpoints, new_totalpoints,  df, item_analysis_df, point_drop, number_correct_by_version, students_by_version, list_of_free_qs=exempts, list_of_skipped_qs=skipped)\n",
    "else:\n",
    "    print(\"Copy the css file over first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grades and displays the N'th entry in the list using a keylist\n",
    "N=random.randint(1,df.shape[0]-1)\n",
    "#for N in range(df.shape[0]-1):\n",
    "#N=9\n",
    "exempts=make_special_question_list(freebies, QIDs)\n",
    "check1=gradeWithKeylist(df.iat[N,2], outs, QIDs, analysis_df, analysis=False, exempt_questions=exempts, skipped_questions=skipped)\n",
    "print(\"Row \"+ str(N)+\": \"+df.iat[N,1]+\", \"+str(df.iat[N,0])+\". Missed \"+str(check1['missed'])+ \". Scored \"+str(check1['score'])+\"/\"+str(new_totalpoints))\n",
    "print('That is: '+str(100*check1['score']/new_totalpoints)+'% with '+str(point_drop)+' points dropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srl No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Missed</th>\n",
       "      <th>Score</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1062</td>\n",
       "      <td>WHEAT EMMA</td>\n",
       "      <td>1310401012334330114</td>\n",
       "      <td>vE: 5, 11, 13, 18</td>\n",
       "      <td>42</td>\n",
       "      <td>82.352941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Srl No        Name              Answers             Missed  Score  \\\n",
       "126  1062   WHEAT EMMA  1310401012334330114  vE: 5, 11, 13, 18  42      \n",
       "\n",
       "     Percentage  \n",
       "126  82.352941   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Searches the results by name. Enter a name or part of a name in string_to_search below\n",
    "string_to_search = \"wheat\"\n",
    "string_to_search = string_to_search.upper()\n",
    "df[df['Name'].str.contains(string_to_search)] # code to search by name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEVELOPMENT AREA\n",
    "## All code below is in development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd=check1['missed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace(string): \n",
    "    return string.replace(\" \", \"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd = remove_whitespace(msd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myconfig import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freebies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_pointlists =[sum(x) for x in pointlist]\n",
    "the_common_sum = set(sum_pointlists)\n",
    "assert((len(the_common_sum)==1))\n",
    "list(the_common_sum)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert((len(the_common_sum)==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(the_common_sum)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstfiles=glob.glob(\"*.tst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstfiles[0][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstnames=[x[:-5] for x in tstfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names = list(set(tstnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(name_list): \n",
    "    return max(set(name_list), key = name_list.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent(tstnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
